from pandas import read_csv, read_excel, read_table, concat, Series
from numpy import ones
import joblib
import os


def read_file(file_path, index_col=0):
    """
    Read files, which supports common data format .csv, .tsv, .xlsx and R-table in .txt format.    
    Notice that while an excel file has several data sheet, this function will return a python dict with corresponding sheet name as dict keys.    

    Args:
        file_path (str): The path to data.
        index_col (int or str): Default is 0. The column index or name to set as the index of dataframe. Set None to ignore.

    Returns:
        pandas.DataFrame: Data or a dict to data sheets
    """
    # sparse csv, tsv or excel
    file_type = file_path.split(".")[-1]
    if file_type == "csv":
        file = read_csv(file_path, index_col=index_col)
    elif file_type == "tsv":
        file_a = read_csv(file_path, sep=" ", index_col=index_col)
        file_b = read_csv(file_path, sep="\t", index_col=index_col)
        if file_a.isna().mean().mean() > file_b.isna().mean().mean():
            file = file_b
        else:
            file = file_a

    elif file_type in ["xls", "xlsx", "xlsm", "xlsb"]:
        file = read_excel(file_path, sheet_name=None, index_col=index_col)
        if len(file) == 1:
            file = file[list(file.keys())[0]]

    elif file_type == "txt":
        file = read_table(file_path, index_col=index_col)
    else:
        print(
            "Not support input type. Must be one of .csv, .tsv, .xls, .xlsx formate."
        )
        file = None
    return file


def read_multiple_groups(file_path_list, transpose=False, index_col=0):
    """
    This function will do:    
        1. read files in    
        2. assign y according to the read-in order    
        3. concat all datas in row    

    When you have several groups of data in seperate files, it can help you read them in.    
    y may be used for group diffirence analysis, or you can just through it away.

    Args:
        file_path_list (list of str): 
        transpose (bool, optional): _description_. Defaults to False.
        index_col (int, optional): _description_. Defaults to 0.

    Returns:
        x (pandas.DataFrame): A dataframe generated by a stacking of sick and healthy dataframe    
        y (pandas.Series): A 1-D array records each row's source order in file_path_list.
    """

    # sparse csv, tsv or excel
    datas = []
    group_label = []
    label = 0
    for path in file_path_list:
        group = read_file(path, index_col)
        if transpose:
            group = group.T

        datas.append(group)
        group_label.append(
            Series(ones(group.shape[0]) * label, index=group.index))
        label += 1

    x = concat(datas, axis=0)
    y = concat(group_label, axis=0)
    return x, y

def save_model(model_obj, save_path, save_name, overide = False):
    """
    Saving the model_obj by joblib in pickle format.

    Args:
        model_obj (object): The model to save.
        save_path (str): The path to saving folder.
        save_name (str): the saving filename of model.
        overide (bool, optional): whether to overide if the save_name has already exist in save_path. Defaults to False.
    """
    if not save_path[-1] == "/":
        save_path = save_path+"/"

    if not os.path.exists(save_path):
        print(save_path, " does not exist yet. we will try to create it.")
        os.makedirs(save_path)
        
    if os.path.exists(save_path+save_name):
        print(save_name, " has already exist in ", save_path)
        if overide:
            print("It will be overide.")
            joblib.dump(model_obj, save_path+ save_name)
        else:
            print("please choose another model save_name or set overide to True which will replace the existing one")
    else:
        joblib.dump(model_obj, save_path+ save_name)

def load_model(save_path, save_name = None):
    """
    load saved model.

    Args:
        save_path (str): The path to saving folder.
        save_name (str): the saving filename of model.

    Returns:
        object: the saved model.
    """
    if save_name:
        if not save_path[-1] == "/":
            save_path = save_path+"/"

        return joblib.load(save_path+save_name)
    else:
        # lazy mode
        return joblib.load(save_path)