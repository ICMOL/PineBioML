<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>PineBioML.selection.classification API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>PineBioML.selection.classification</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="PineBioML.selection.classification.AdaBoost_selection"><code class="flex name class">
<span>class <span class="ident">AdaBoost_selection</span></span>
<span>(</span><span>k=None,<br>z_importance_threshold=1.0,<br>unbalanced=True,<br>n_iter=128,<br>learning_rate=0.01,<br>n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AdaBoost_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Using AdaBoost to scoring (gini impurity / entropy) features.

    Warning: If data is too easy, boosting methods is difficult to give score to all features.
    &#34;&#34;&#34;

    def __init__(self,
                 k=None,
                 z_importance_threshold=1.,
                 unbalanced=True,
                 n_iter=128,
                 learning_rate=0.01,
                 n_cv=5):
        &#34;&#34;&#34;
        Args:
            n_iter (int, optional): Number of trees also number of iteration to boost. Defaults to 64.
            learning_rate (float, optional): boosting learning rate. Defaults to 0.01.
            unbalanced (bool, optional): True to imply class weight to samples. Defaults to False.
        &#34;&#34;&#34;
        from sklearn.ensemble import AdaBoostClassifier
        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)
        self.unbalanced = unbalanced
        self.kernel = AdaBoostClassifier(
            n_estimators=n_iter,
            learning_rate=learning_rate,
            random_state=142,
        )
        self.name = &#34;AdaBoost&#34; + str(n_iter)

    def reference(self) -&gt; dict[str, str]:

        refer = super().reference()
        refer[
            self.name() +
            &#34; document&#34;] = &#34;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier.feature_importances_&#34;
        return refer

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using AdaBoost to scoring (gini impurity / entropy) features.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        print(&#34;I don&#39;t have a progress bar but I am running&#34;)
        if self.unbalanced:
            sample_weight = compute_sample_weight(class_weight=&#34;balanced&#34;, y=y)
        else:
            sample_weight = np.ones(len(y))
        self.kernel.fit(x, y, sample_weight)
        score = self.kernel.feature_importances_
        scores = pd.Series(score, index=x.columns,
                           name=self.name).sort_values(ascending=False)
        return scores</code></pre>
</details>
<div class="desc"><p>Using AdaBoost to scoring (gini impurity / entropy) features.</p>
<p>Warning: If data is too easy, boosting methods is difficult to give score to all features.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_iter</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trees also number of iteration to boost. Defaults to 64.</dd>
<dt><strong><code>learning_rate</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>boosting learning rate. Defaults to 0.01.</dd>
<dt><strong><code>unbalanced</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>True to imply class weight to samples. Defaults to False.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="PineBioML.selection.classification.AdaBoost_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using AdaBoost to scoring (gini impurity / entropy) features.

    Returns:
        pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
    &#34;&#34;&#34;
    print(&#34;I don&#39;t have a progress bar but I am running&#34;)
    if self.unbalanced:
        sample_weight = compute_sample_weight(class_weight=&#34;balanced&#34;, y=y)
    else:
        sample_weight = np.ones(len(y))
    self.kernel.fit(x, y, sample_weight)
    score = self.kernel.feature_importances_
    scores = pd.Series(score, index=x.columns,
                       name=self.name).sort_values(ascending=False)
    return scores</code></pre>
</details>
<div class="desc"><p>Using AdaBoost to scoring (gini impurity / entropy) features.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>pandas.DataFrame</code></dt>
<dd>The score for each feature. Some elements may be empty.</dd>
</dl></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="PineBioML.selection.classification.DT_selection"><code class="flex name class">
<span>class <span class="ident">DT_selection</span></span>
<span>(</span><span>k=None, z_importance_threshold=1.0, bins=10, q=0.05, strategy='c45', n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DT_selection(SelectionPipeline):
    &#34;&#34;&#34;
    A child class of SelectionPipeline.

    Using Decision stump (a single Decision tree) to scoring features.    
    What we do here is:    
        1. normalize data    
        2. transform data into frequency domain by binning through a certain column and applying value_counts    
        3. estimate entropy    
        4. compute c4.5    
    &#34;&#34;&#34;

    def __init__(self,
                 k=None,
                 z_importance_threshold=1.,
                 bins=10,
                 q=0.05,
                 strategy=&#34;c45&#34;,
                 n_cv=5):
        &#34;&#34;&#34;
        Args:
            bins (int, optional): Bins to esimate data distribution entropy. Defaults to 10.
            q (float, optional): Clip data values out of [q, 1-q] percentile to reduce the affect of outliers while estimate entropy. Defaults to 0.05.
            strategy (str, optional): One of {&#34;gini&#34;, &#34;c45&#34;}. The strategy to build decision tree. Defaults to &#34;c45&#34;.
        &#34;&#34;&#34;
        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)
        self.bins = bins - 1
        self.q = q
        self.strategy = strategy
        self.name = &#34;DT_score_&#34; + self.strategy

    def reference(self) -&gt; dict[str, str]:
        refer = super().reference()
        refer[self.name() +
              &#34; document&#34;] = &#34;PineBioML.selection.classification.DT_selection&#34;
        refer[
            &#34; publication&#34;] = &#34;Quinlan, J. R. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, 1993.&#34;
        return refer

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using Decision stump (a single Decision tree) to scoring features. Though, single layer stump is equivalent to compare the id3/c4.5 score directly.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        self.y_encoder = OneHotEncoder(sparse_output=False)
        y = self.y_encoder.fit_transform(y.to_numpy().reshape(
            -1, 1)).argmax(axis=-1)

        if self.strategy == &#39;c45&#39;:
            score = self.best_splits_c45_batch_optimized(x, y)
        elif self.strategy == &#39;gini&#39;:
            score = self.best_splits_gini_batch_optimized(x, y)

        scores = pd.Series(score, index=x.columns,
                           name=self.name).sort_values(ascending=False)
        return scores

    def compute_gain_ratio(self, y_sorted, n_classes, n, eps=1e-12):
        &#34;&#34;&#34;
        Compute best Gain Ratio for one sorted feature
        &#34;&#34;&#34;
        # one-hot encode
        one_hot = np.eye(n_classes)[y_sorted]

        # cumulative counts (exclude last split)
        left_counts = np.cumsum(one_hot, axis=0)[:-1]
        total_counts = left_counts[-1]
        right_counts = total_counts - left_counts

        # sample counts
        left_totals = np.arange(1, n)
        right_totals = n - left_totals

        # ---- entropy computation ----
        def entropy(counts, totals):
            probs = counts / totals[:, None]
            probs = np.clip(probs, eps, 1.0)
            return -np.sum(probs * np.log2(probs), axis=1)

        # parent entropy
        parent_probs = total_counts / n
        parent_probs = np.clip(parent_probs, eps, 1.0)
        parent_entropy = -np.sum(parent_probs * np.log2(parent_probs))

        # left / right entropy
        entropy_left = entropy(left_counts, left_totals)
        entropy_right = entropy(right_counts, right_totals)

        # information gain
        info_gain = parent_entropy - (
            (left_totals / n) * entropy_left +
            (right_totals / n) * entropy_right
        )

        # split information
        p_left = left_totals / n
        p_right = right_totals / n
        split_info = -(
            p_left * np.log2(np.clip(p_left, eps, 1.0)) +
            p_right * np.log2(np.clip(p_right, eps, 1.0))
        )

        # gain ratio
        gain_ratio = info_gain / np.clip(split_info, eps, None)

        # C4.5 chooses the **maximum** gain ratio
        return np.max(gain_ratio)

    def compute_gini(self, y_sorted, n_classes, n):
        one_hot = np.eye(n_classes)[y_sorted]
        left_counts = np.cumsum(one_hot, axis=0)[:-1]

        # right counts
        total_counts = left_counts[-1]
        right_counts = total_counts - left_counts

        # total counts
        left_totals = np.arange(1, n)
        right_totals = n - left_totals

        # vectorizing left &amp; right Gini computing
        gini_left = 1.0 - np.sum(
            (left_counts / left_totals[:, np.newaxis])**2, axis=1)
        gini_right = 1.0 - np.sum(
            (right_counts / right_totals[:, np.newaxis])**2, axis=1)

        # weighted Gini
        weighted_gini = (left_totals * gini_left +
                         right_totals * gini_right) / n
        return np.min(weighted_gini)

    def best_splits_gini_batch_optimized(self, X, Y):
        &#34;&#34;&#34;
        compute gini in batch
        
        Args:
            X (pandas.DataFrame): (n_samples, n_features) in numerical dtypes.
            y (pandas.Series): (n_samples,) in int.
        
        return:
            best_ginis: (n_features,)
            best_thresholds: (n_features,) placeholder, we don&#39;t need it here
        &#34;&#34;&#34;
        x = X  #.to_numpy()
        y = Y  #.to_numpy().astype(np.int8)
        n, n_features = X.shape
        n_classes = y.max() + 1

        # sorting all the features
        sort_idx = np.argsort(x, axis=0)

        #X_sorted = np.take_along_axis(X, sort_idx, axis=0)
        y_sorted_all = np.take_along_axis(np.tile(y[:, None], (1, n_features)),
                                          sort_idx,
                                          axis=0)

        best_ginis = np.ones(n_features)

        with parallel_config(backend=&#39;loky&#39;, n_jobs=-1):
            best_ginis = Parallel()(
                delayed(self.compute_gini)(y_sorted_all[:, i], n_classes, n)
                for i in tqdm(np.arange(n_features)))

        return best_ginis
    
    def best_splits_c45_batch_optimized(self, X, Y):
        &#34;&#34;&#34;
        compute C4.5 gain ratio in batch
        
        Args:
            X (pandas.DataFrame): (n_samples, n_features)
            Y (pandas.Series): (n_samples,) int labels
        
        return:
            best_gain_ratios: (n_features,)
        &#34;&#34;&#34;
        x = X
        y = Y
        n, n_features = X.shape
        n_classes = y.max() + 1

        # sort indices per feature
        sort_idx = np.argsort(x, axis=0)

        # reorder y for each feature
        y_sorted_all = np.take_along_axis(
            np.tile(y[:, None], (1, n_features)),
            sort_idx,
            axis=0
        )

        with parallel_config(backend=&#39;loky&#39;, n_jobs=-1):
            best_gain_ratios = Parallel()(
                delayed(self.compute_gain_ratio)(
                    y_sorted_all[:, i], n_classes, n
                )
                for i in tqdm(range(n_features))
            )

        return np.array(best_gain_ratios)</code></pre>
</details>
<div class="desc"><p>A child class of SelectionPipeline.</p>
<p>Using Decision stump (a single Decision tree) to scoring features.
<br>
What we do here is:
<br>
1. normalize data
<br>
2. transform data into frequency domain by binning through a certain column and applying value_counts
<br>
3. estimate entropy
<br>
4. compute c4.5
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>bins</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Bins to esimate data distribution entropy. Defaults to 10.</dd>
<dt><strong><code>q</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Clip data values out of [q, 1-q] percentile to reduce the affect of outliers while estimate entropy. Defaults to 0.05.</dd>
<dt><strong><code>strategy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>One of {"gini", "c45"}. The strategy to build decision tree. Defaults to "c45".</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="PineBioML.selection.classification.DT_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using Decision stump (a single Decision tree) to scoring features. Though, single layer stump is equivalent to compare the id3/c4.5 score directly.

    Returns:
        pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
    &#34;&#34;&#34;
    self.y_encoder = OneHotEncoder(sparse_output=False)
    y = self.y_encoder.fit_transform(y.to_numpy().reshape(
        -1, 1)).argmax(axis=-1)

    if self.strategy == &#39;c45&#39;:
        score = self.best_splits_c45_batch_optimized(x, y)
    elif self.strategy == &#39;gini&#39;:
        score = self.best_splits_gini_batch_optimized(x, y)

    scores = pd.Series(score, index=x.columns,
                       name=self.name).sort_values(ascending=False)
    return scores</code></pre>
</details>
<div class="desc"><p>Using Decision stump (a single Decision tree) to scoring features. Though, single layer stump is equivalent to compare the id3/c4.5 score directly.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>pandas.DataFrame</code></dt>
<dd>The score for each feature. Some elements may be empty.</dd>
</dl></div>
</dd>
<dt id="PineBioML.selection.classification.DT_selection.best_splits_c45_batch_optimized"><code class="name flex">
<span>def <span class="ident">best_splits_c45_batch_optimized</span></span>(<span>self, X, Y)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def best_splits_c45_batch_optimized(self, X, Y):
    &#34;&#34;&#34;
    compute C4.5 gain ratio in batch
    
    Args:
        X (pandas.DataFrame): (n_samples, n_features)
        Y (pandas.Series): (n_samples,) int labels
    
    return:
        best_gain_ratios: (n_features,)
    &#34;&#34;&#34;
    x = X
    y = Y
    n, n_features = X.shape
    n_classes = y.max() + 1

    # sort indices per feature
    sort_idx = np.argsort(x, axis=0)

    # reorder y for each feature
    y_sorted_all = np.take_along_axis(
        np.tile(y[:, None], (1, n_features)),
        sort_idx,
        axis=0
    )

    with parallel_config(backend=&#39;loky&#39;, n_jobs=-1):
        best_gain_ratios = Parallel()(
            delayed(self.compute_gain_ratio)(
                y_sorted_all[:, i], n_classes, n
            )
            for i in tqdm(range(n_features))
        )

    return np.array(best_gain_ratios)</code></pre>
</details>
<div class="desc"><p>compute C4.5 gain ratio in batch</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>(n_samples, n_features)</dd>
<dt><strong><code>Y</code></strong> :&ensp;<code>pandas.Series</code></dt>
<dd>(n_samples,) int labels</dd>
</dl>
<p>return:
best_gain_ratios: (n_features,)</p></div>
</dd>
<dt id="PineBioML.selection.classification.DT_selection.best_splits_gini_batch_optimized"><code class="name flex">
<span>def <span class="ident">best_splits_gini_batch_optimized</span></span>(<span>self, X, Y)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def best_splits_gini_batch_optimized(self, X, Y):
    &#34;&#34;&#34;
    compute gini in batch
    
    Args:
        X (pandas.DataFrame): (n_samples, n_features) in numerical dtypes.
        y (pandas.Series): (n_samples,) in int.
    
    return:
        best_ginis: (n_features,)
        best_thresholds: (n_features,) placeholder, we don&#39;t need it here
    &#34;&#34;&#34;
    x = X  #.to_numpy()
    y = Y  #.to_numpy().astype(np.int8)
    n, n_features = X.shape
    n_classes = y.max() + 1

    # sorting all the features
    sort_idx = np.argsort(x, axis=0)

    #X_sorted = np.take_along_axis(X, sort_idx, axis=0)
    y_sorted_all = np.take_along_axis(np.tile(y[:, None], (1, n_features)),
                                      sort_idx,
                                      axis=0)

    best_ginis = np.ones(n_features)

    with parallel_config(backend=&#39;loky&#39;, n_jobs=-1):
        best_ginis = Parallel()(
            delayed(self.compute_gini)(y_sorted_all[:, i], n_classes, n)
            for i in tqdm(np.arange(n_features)))

    return best_ginis</code></pre>
</details>
<div class="desc"><p>compute gini in batch</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>(n_samples, n_features) in numerical dtypes.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pandas.Series</code></dt>
<dd>(n_samples,) in int.</dd>
</dl>
<p>return:
best_ginis: (n_features,)
best_thresholds: (n_features,) placeholder, we don't need it here</p></div>
</dd>
<dt id="PineBioML.selection.classification.DT_selection.compute_gain_ratio"><code class="name flex">
<span>def <span class="ident">compute_gain_ratio</span></span>(<span>self, y_sorted, n_classes, n, eps=1e-12)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_gain_ratio(self, y_sorted, n_classes, n, eps=1e-12):
    &#34;&#34;&#34;
    Compute best Gain Ratio for one sorted feature
    &#34;&#34;&#34;
    # one-hot encode
    one_hot = np.eye(n_classes)[y_sorted]

    # cumulative counts (exclude last split)
    left_counts = np.cumsum(one_hot, axis=0)[:-1]
    total_counts = left_counts[-1]
    right_counts = total_counts - left_counts

    # sample counts
    left_totals = np.arange(1, n)
    right_totals = n - left_totals

    # ---- entropy computation ----
    def entropy(counts, totals):
        probs = counts / totals[:, None]
        probs = np.clip(probs, eps, 1.0)
        return -np.sum(probs * np.log2(probs), axis=1)

    # parent entropy
    parent_probs = total_counts / n
    parent_probs = np.clip(parent_probs, eps, 1.0)
    parent_entropy = -np.sum(parent_probs * np.log2(parent_probs))

    # left / right entropy
    entropy_left = entropy(left_counts, left_totals)
    entropy_right = entropy(right_counts, right_totals)

    # information gain
    info_gain = parent_entropy - (
        (left_totals / n) * entropy_left +
        (right_totals / n) * entropy_right
    )

    # split information
    p_left = left_totals / n
    p_right = right_totals / n
    split_info = -(
        p_left * np.log2(np.clip(p_left, eps, 1.0)) +
        p_right * np.log2(np.clip(p_right, eps, 1.0))
    )

    # gain ratio
    gain_ratio = info_gain / np.clip(split_info, eps, None)

    # C4.5 chooses the **maximum** gain ratio
    return np.max(gain_ratio)</code></pre>
</details>
<div class="desc"><p>Compute best Gain Ratio for one sorted feature</p></div>
</dd>
<dt id="PineBioML.selection.classification.DT_selection.compute_gini"><code class="name flex">
<span>def <span class="ident">compute_gini</span></span>(<span>self, y_sorted, n_classes, n)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_gini(self, y_sorted, n_classes, n):
    one_hot = np.eye(n_classes)[y_sorted]
    left_counts = np.cumsum(one_hot, axis=0)[:-1]

    # right counts
    total_counts = left_counts[-1]
    right_counts = total_counts - left_counts

    # total counts
    left_totals = np.arange(1, n)
    right_totals = n - left_totals

    # vectorizing left &amp; right Gini computing
    gini_left = 1.0 - np.sum(
        (left_counts / left_totals[:, np.newaxis])**2, axis=1)
    gini_right = 1.0 - np.sum(
        (right_counts / right_totals[:, np.newaxis])**2, axis=1)

    # weighted Gini
    weighted_gini = (left_totals * gini_left +
                     right_totals * gini_right) / n
    return np.min(weighted_gini)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="PineBioML.selection.classification.Lasso_selection"><code class="flex name class">
<span>class <span class="ident">Lasso_selection</span></span>
<span>(</span><span>k=None, z_importance_threshold=1.0, unbalanced=True, n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Lasso_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Using Lasso (L1 penalty) regression as scoring method. L1 penalty will force feature weights to be zeros.    
    As the penalty increases, more and more regression coefficients vanish and the ones coresponding to important variables will remain.    

    The Lasso_selection is base on [Lasso Lars](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html).    

    Currently, this do not support Lasso + logistic regression, so:    
        Binary classification problem will be regarded as a regression to {0, 1}.    
        Multi-class classification problem will be devided into ovr (one vs rest) classification and the score of features over ovr will be combined by average weighted class weight.    

    ~~Lasso_selection will use grid search to find out when all weights vanish.    ~~
    &#34;&#34;&#34;

    def __init__(self,
                 k=None,
                 z_importance_threshold=1.,
                 unbalanced=True,
                 n_cv=5):
        &#34;&#34;&#34;
        Args:
            unbalanced (bool, optional): False to imply class weight to samples. Defaults to True.
        &#34;&#34;&#34;
        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)

        # parameters
        self.regression = True
        self.unbalanced = unbalanced
        self.name = &#34;LassoLars&#34;

    def reference(self) -&gt; dict[str, str]:
        refer = super().reference()
        refer[
            self.name() +
            &#34; document&#34;] = &#34;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html&#34;
        refer[
            &#34; publication Lasso 1&#34;] = &#34;https://projecteuclid.org/journals/annals-of-statistics/volume-37/issue-5A/High-dimensional-variable-selection/10.1214/08-AOS646.full&#34;
        refer[
            &#34; publication Lasso 2&#34;] = &#34;https://www.tandfonline.com/doi/abs/10.1198/016214506000000735?casa_token=5HDhtyCfh40AAAAA:4NxSU97CZubZVpReaQNsSBpqA10_xNhspTQobPnb_z2YXe3Wf-HBHV8OygbqUkmJQPt2Jmp7ZlJPWd0&#34;
        refer[&#34; publication Lars&#34;] = &#34;https://arxiv.org/pdf/math/0406456&#34;

        return refer

    def create_kernel(self, C=1e-2):
        &#34;&#34;&#34;
        Create diffirent kernel according to opjective.

        Args:
            C (float): The coefficient to L1 penalty.

        Returns:
            sklearn.linearmodel: a kernel of sklearn linearmodel
        
        TODO:
            1. auto C tuner or adapter.
            
        &#34;&#34;&#34;

        return LassoLars(alpha=C, random_state=142)

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using Lasso Lars regression as scoring method.
                
        &#34;&#34;&#34;

        x_train = x.copy()
        y_train = y.copy()

        self.y_encoder = OneHotEncoder(sparse_output=False)
        self.y_encoder.fit(y.to_numpy().reshape(-1, 1))
        y_train = self.y_encoder.transform(y_train.to_numpy().reshape(-1, 1))

        kernel = self.create_kernel()

        ### TODO: Sample weight for Lars.
        if y_train.shape[1] == 2:
            # Binary classification
            task_set = [1]
        else:
            # multi-class classification
            ### TODO: Multinomial classfication for Lars.
            task_set = range(y_train.shape[1])

        result = []
        for i in task_set:
            # TODO: cross validation, alpha interpolation
            y = y_train[:, i]
            y = (y - y.mean()) / y.std()
            kernel.fit(x_train, y)

            coef = np.clip(kernel.coef_path_.T, -1, 1)
            alpha = kernel.alphas_
            col = kernel.feature_names_in_

            result.append(pd.DataFrame(coef, columns=col, index=alpha))

        var_dropout_alpha = []
        for s in result:
            # the right end side(alpha) of the range that variable has a non-zero lars coefficient.
            tmp = (s != 0).idxmax(axis=0).replace(s.index[0], 0)**2

            # normalizing each task.
            tmp = tmp / tmp.max()
            var_dropout_alpha.append(tmp)

        # collect the results
        self.result = result
        scores = np.sqrt(sum(var_dropout_alpha)).sort_values(ascending=False)
        scores.name = self.name
        return scores

    def Plotting(self):
        super().Plotting()

        global_selected = self.selected_score.index
        for i_th in range(len(self.result)):
            s = self.result[-i_th - 1]

            # get the features ever alive.
            alive_col = s.columns[(s != 0).any(axis=0)]

            # show the label of the top-5 long-lived features
            noting_col = (s != 0).idxmax(axis=0).replace(
                s.index[0], 0).sort_values().tail(5).index

            plt_cmap = plt.get_cmap(&#34;Blues&#34;)
            plt_norm = plt.Normalize(vmin=0, vmax=s.index[1])
            fig, ax = plt.subplots(layout=&#39;constrained&#39;)

            for col in alive_col:
                var_coef = s[col]
                self.plot_coef_1var(
                    alpha=var_coef.index,
                    coef=var_coef.values,
                    global_selected=col in global_selected,
                    coef_name=col if col in noting_col else None,
                    cmap=plt_cmap,
                    norm=plt_norm,
                )

            plt.axhline(y=0, color=&#34;grey&#34;, linestyle=&#34;--&#34;)
            plt.xlabel(&#34;alpha&#34;)
            plt.ylabel(&#34;coefficient&#34;)
            plt.title(&#34;class-{} Lasso&#34;.format(
                self.y_encoder.categories_[0][i_th]))

            scalar_mappable = ScalarMappable(norm=plt_norm, cmap=plt_cmap)
            fig.colorbar(scalar_mappable,
                         ax=ax,
                         orientation=&#39;vertical&#39;,
                         label=&#39;Variable dropout alpha&#39;)
            plt.xscale(&#39;log&#39;)
            legend_elements = [
                Line2D([0], [0],
                       color=&#34;b&#34;,
                       label=&#34;Globally important&#34;,
                       linestyle=&#34;solid&#34;),
                Line2D([0], [0],
                       color=&#34;b&#34;,
                       label=&#34;Partially important&#34;,
                       linestyle=&#34;--&#34;),
            ]
            ax.legend(handles=legend_elements, loc=&#34;upper right&#34;)
            plt.show()

    def plot_coef_1var(self, alpha, coef, global_selected, coef_name, cmap,
                       norm):
        # plot the coef curve
        linestyle = &#34;solid&#34; if global_selected else &#34;--&#34;

        alive = coef != 0
        alive[alive.argmax() - 1] = True

        alpha = alpha[alive]
        coef = coef[alive]

        plt.plot(alpha,
                 coef,
                 label=coef_name,
                 c=cmap(norm(alpha.max())),
                 linestyle=linestyle)

        # plot the annotate
        if coef_name is not None:
            annotate_idx = np.abs(coef).argmax()
            annotate_coor = (alpha[annotate_idx], coef[annotate_idx])
            text_coor = (alpha[annotate_idx], coef[annotate_idx])
            plt.annotate(
                coef_name,
                xy=annotate_coor,
                xytext=text_coor,
            )</code></pre>
</details>
<div class="desc"><p>Using Lasso (L1 penalty) regression as scoring method. L1 penalty will force feature weights to be zeros.
<br>
As the penalty increases, more and more regression coefficients vanish and the ones coresponding to important variables will remain.
</p>
<p>The Lasso_selection is base on <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html">Lasso Lars</a>.
</p>
<p>Currently, this do not support Lasso + logistic regression, so:
<br>
Binary classification problem will be regarded as a regression to {0, 1}.
<br>
Multi-class classification problem will be devided into ovr (one vs rest) classification and the score of features over ovr will be combined by average weighted class weight.
</p>
<p>~~Lasso_selection will use grid search to find out when all weights vanish.
~~</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>unbalanced</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>False to imply class weight to samples. Defaults to True.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="PineBioML.selection.classification.Lasso_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using Lasso Lars regression as scoring method.
            
    &#34;&#34;&#34;

    x_train = x.copy()
    y_train = y.copy()

    self.y_encoder = OneHotEncoder(sparse_output=False)
    self.y_encoder.fit(y.to_numpy().reshape(-1, 1))
    y_train = self.y_encoder.transform(y_train.to_numpy().reshape(-1, 1))

    kernel = self.create_kernel()

    ### TODO: Sample weight for Lars.
    if y_train.shape[1] == 2:
        # Binary classification
        task_set = [1]
    else:
        # multi-class classification
        ### TODO: Multinomial classfication for Lars.
        task_set = range(y_train.shape[1])

    result = []
    for i in task_set:
        # TODO: cross validation, alpha interpolation
        y = y_train[:, i]
        y = (y - y.mean()) / y.std()
        kernel.fit(x_train, y)

        coef = np.clip(kernel.coef_path_.T, -1, 1)
        alpha = kernel.alphas_
        col = kernel.feature_names_in_

        result.append(pd.DataFrame(coef, columns=col, index=alpha))

    var_dropout_alpha = []
    for s in result:
        # the right end side(alpha) of the range that variable has a non-zero lars coefficient.
        tmp = (s != 0).idxmax(axis=0).replace(s.index[0], 0)**2

        # normalizing each task.
        tmp = tmp / tmp.max()
        var_dropout_alpha.append(tmp)

    # collect the results
    self.result = result
    scores = np.sqrt(sum(var_dropout_alpha)).sort_values(ascending=False)
    scores.name = self.name
    return scores</code></pre>
</details>
<div class="desc"><p>Using Lasso Lars regression as scoring method.</p></div>
</dd>
<dt id="PineBioML.selection.classification.Lasso_selection.create_kernel"><code class="name flex">
<span>def <span class="ident">create_kernel</span></span>(<span>self, C=0.01)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_kernel(self, C=1e-2):
    &#34;&#34;&#34;
    Create diffirent kernel according to opjective.

    Args:
        C (float): The coefficient to L1 penalty.

    Returns:
        sklearn.linearmodel: a kernel of sklearn linearmodel
    
    TODO:
        1. auto C tuner or adapter.
        
    &#34;&#34;&#34;

    return LassoLars(alpha=C, random_state=142)</code></pre>
</details>
<div class="desc"><p>Create diffirent kernel according to opjective.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>C</code></strong> :&ensp;<code>float</code></dt>
<dd>The coefficient to L1 penalty.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>sklearn.linearmodel</code></dt>
<dd>a kernel of sklearn linearmodel</dd>
</dl>
<h2 id="todo">Todo</h2>
<ol>
<li>auto C tuner or adapter.</li>
</ol></div>
</dd>
<dt id="PineBioML.selection.classification.Lasso_selection.plot_coef_1var"><code class="name flex">
<span>def <span class="ident">plot_coef_1var</span></span>(<span>self, alpha, coef, global_selected, coef_name, cmap, norm)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_coef_1var(self, alpha, coef, global_selected, coef_name, cmap,
                   norm):
    # plot the coef curve
    linestyle = &#34;solid&#34; if global_selected else &#34;--&#34;

    alive = coef != 0
    alive[alive.argmax() - 1] = True

    alpha = alpha[alive]
    coef = coef[alive]

    plt.plot(alpha,
             coef,
             label=coef_name,
             c=cmap(norm(alpha.max())),
             linestyle=linestyle)

    # plot the annotate
    if coef_name is not None:
        annotate_idx = np.abs(coef).argmax()
        annotate_coor = (alpha[annotate_idx], coef[annotate_idx])
        text_coor = (alpha[annotate_idx], coef[annotate_idx])
        plt.annotate(
            coef_name,
            xy=annotate_coor,
            xytext=text_coor,
        )</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="PineBioML.selection.classification.Lightgbm_selection"><code class="flex name class">
<span>class <span class="ident">Lightgbm_selection</span></span>
<span>(</span><span>k=None, z_importance_threshold=1.0, unbalanced=True, n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Lightgbm_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Using Lightgbm to scoring (gini impurity / entropy) features. 

    Warning: If data is too easy, boosting methods is difficult to give score to all features.
    &#34;&#34;&#34;

    def __init__(self,
                 k=None,
                 z_importance_threshold=1.,
                 unbalanced=True,
                 n_cv=5):
        &#34;&#34;&#34;
        Args:
            unbalanced (bool, optional): True to imply class weight to samples. Defaults to False.
        &#34;&#34;&#34;
        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)
        self.unbalanced = unbalanced
        from lightgbm import LGBMClassifier

        self.kernel = LGBMClassifier(learning_rate=0.01,
                                     random_state=142,
                                     subsample=0.7,
                                     subsample_freq=1,
                                     verbosity=-1)
        self.name = &#34;Lightgbm&#34;

    def reference(self) -&gt; dict[str, str]:
        refer = super().reference()
        refer[
            self.name() +
            &#34; document&#34;] = &#34;https://lightgbm.readthedocs.io/en/latest/Parameters.html#saved_feature_importance_type&#34;
        return refer

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using Lightgbm to scoring (gini impurity / entropy) features.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        if self.unbalanced:
            sample_weight = compute_sample_weight(class_weight=&#34;balanced&#34;, y=y)
        else:
            sample_weight = np.ones(len(y))

        self.kernel.fit(x, y, sample_weight=sample_weight)
        score = self.kernel.feature_importances_
        scores = pd.Series(score, index=x.columns,
                           name=self.name).sort_values(ascending=False)
        return scores</code></pre>
</details>
<div class="desc"><p>Using Lightgbm to scoring (gini impurity / entropy) features. </p>
<p>Warning: If data is too easy, boosting methods is difficult to give score to all features.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>unbalanced</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>True to imply class weight to samples. Defaults to False.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="PineBioML.selection.classification.Lightgbm_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using Lightgbm to scoring (gini impurity / entropy) features.

    Returns:
        pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
    &#34;&#34;&#34;
    if self.unbalanced:
        sample_weight = compute_sample_weight(class_weight=&#34;balanced&#34;, y=y)
    else:
        sample_weight = np.ones(len(y))

    self.kernel.fit(x, y, sample_weight=sample_weight)
    score = self.kernel.feature_importances_
    scores = pd.Series(score, index=x.columns,
                       name=self.name).sort_values(ascending=False)
    return scores</code></pre>
</details>
<div class="desc"><p>Using Lightgbm to scoring (gini impurity / entropy) features.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>pandas.DataFrame</code></dt>
<dd>The score for each feature. Some elements may be empty.</dd>
</dl></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="PineBioML.selection.classification.RF_selection"><code class="flex name class">
<span>class <span class="ident">RF_selection</span></span>
<span>(</span><span>k=None, z_importance_threshold=1.0, unbalanced=True, strategy='gini', n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RF_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Using random forest to scoring features by gini/entropy gain.    
    We do not provide permutation importance(VI, variable importance) here.

    &#34;&#34;&#34;

    def __init__(self,
                 k=None,
                 z_importance_threshold=1.,
                 unbalanced=True,
                 strategy=&#34;gini&#34;,
                 n_cv=5):
        &#34;&#34;&#34;
        Args:
            strategy (str, optional): Scoring strategy, one of {&#34;gini&#34;, &#34;entropy&#34;}. Defaults to &#34;gini&#34;.
            unbalanced (bool, optional): True to imply class weight to samples. Defaults to True.
        &#34;&#34;&#34;
        from sklearn.ensemble import RandomForestClassifier
        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)
        self.strategy = strategy
        if unbalanced:
            class_weight = &#34;balanced&#34;
        else:
            class_weight = None

        self.kernel = RandomForestClassifier(n_estimators=100,
                                             n_jobs=-1,
                                             max_samples=0.7,
                                             class_weight=class_weight,
                                             criterion=strategy,
                                             verbose=0,
                                             random_state=142,
                                             min_samples_leaf=2)

        self.name = &#34;RandomForest_&#34; + self.strategy

    def reference(self) -&gt; dict[str, str]:

        refer = super().reference()
        refer[self.name() + &#34; document&#34;] = &#34;&#34;
        refer[
            &#34; publication cons&#34;] = &#34;https://link.springer.com/article/10.1186/1471-2105-8-25&#34;
        refer[
            &#34; publication pros 1&#34;] = &#34;https://link.springer.com/article/10.1186/1471-2105-10-213&#34;
        refer[
            &#34; publication pros 2&#34;] = &#34;https://www.sciencedirect.com/science/article/pii/S0167947307003076&#34;
        refer[
            &#34; publication survey&#34;] = &#34;https://www.cs.cmu.edu/~qyj/papersA08/11-rfbook.pdf&#34;

        return refer

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using random forest to scoring (gini impurity / entropy) features.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        self.kernel.n_estimators = round(2 * np.sqrt(x.shape[1]) *
                                         np.log(x.shape[1]))
        with parallel_config(backend=&#39;loky&#39;):
            self.kernel.fit(x, y)
        score = self.kernel.feature_importances_
        scores = pd.Series(score, index=x.columns,
                           name=self.name).sort_values(ascending=False)
        return scores</code></pre>
</details>
<div class="desc"><p>Using random forest to scoring features by gini/entropy gain.
<br>
We do not provide permutation importance(VI, variable importance) here.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>strategy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Scoring strategy, one of {"gini", "entropy"}. Defaults to "gini".</dd>
<dt><strong><code>unbalanced</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>True to imply class weight to samples. Defaults to True.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="PineBioML.selection.classification.RF_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using random forest to scoring (gini impurity / entropy) features.

    Returns:
        pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
    &#34;&#34;&#34;
    self.kernel.n_estimators = round(2 * np.sqrt(x.shape[1]) *
                                     np.log(x.shape[1]))
    with parallel_config(backend=&#39;loky&#39;):
        self.kernel.fit(x, y)
    score = self.kernel.feature_importances_
    scores = pd.Series(score, index=x.columns,
                       name=self.name).sort_values(ascending=False)
    return scores</code></pre>
</details>
<div class="desc"><p>Using random forest to scoring (gini impurity / entropy) features.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>pandas.DataFrame</code></dt>
<dd>The score for each feature. Some elements may be empty.</dd>
</dl></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="PineBioML.selection.classification.SVM_selection"><code class="flex name class">
<span>class <span class="ident">SVM_selection</span></span>
<span>(</span><span>k=None, z_importance_threshold=1.0, n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SVM_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Using the support vector of linear support vector classifier as scoring method.    

    SVM_selection is scale sensitive in result.    

    &lt;&lt;Feature Ranking Using Linear SVM&gt;&gt; section 3.2

    &#34;&#34;&#34;

    def __init__(self, k=None, z_importance_threshold=1., n_cv=5):
        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)
        self.kernel = LinearSVC(dual=&#34;auto&#34;,
                                class_weight=&#34;balanced&#34;,
                                random_state=142)
        self.name = &#34;SVM&#34;

    def reference(self) -&gt; dict[str, str]:
        refer = super().reference()
        refer[
            self.name() +
            &#34; document&#34;] = &#34;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html&#34;
        refer[
            &#34; publication - section 3.2&#34;] = &#34;https://www.csie.ntu.edu.tw/~cjlin/papers/causality.pdf&#34;
        return refer

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using the support vector of linear support vector classifier as scoring method.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        self.kernel.fit(x, y)
        svm_weights = np.abs(self.kernel.coef_).sum(axis=0)
        svm_weights /= svm_weights.sum()

        scores = pd.Series(svm_weights, index=x.columns,
                           name=self.name).sort_values(ascending=False)
        return scores</code></pre>
</details>
<div class="desc"><p>Using the support vector of linear support vector classifier as scoring method.
</p>
<p>SVM_selection is scale sensitive in result.
</p>
<p>&lt;<Feature Ranking Using Linear SVM>&gt; section 3.2</p>
<p>Initialize the selection pipeline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>select top k important feature. k = -1 means selecting all, k = None means selecting the feature that have standarized score &gt; 1. Default = None</dd>
<dt><strong><code>z_importance_threshold</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The threshold to picking features. Defaults to 1.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="PineBioML.selection.classification.SVM_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using the support vector of linear support vector classifier as scoring method.

    Returns:
        pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
    &#34;&#34;&#34;
    self.kernel.fit(x, y)
    svm_weights = np.abs(self.kernel.coef_).sum(axis=0)
    svm_weights /= svm_weights.sum()

    scores = pd.Series(svm_weights, index=x.columns,
                       name=self.name).sort_values(ascending=False)
    return scores</code></pre>
</details>
<div class="desc"><p>Using the support vector of linear support vector classifier as scoring method.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>pandas.DataFrame</code></dt>
<dd>The score for each feature. Some elements may be empty.</dd>
</dl></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="PineBioML.selection.classification.XGboost_selection"><code class="flex name class">
<span>class <span class="ident">XGboost_selection</span></span>
<span>(</span><span>k=None, z_importance_threshold=1.0, unbalanced=True, n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class XGboost_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Using XGboost to scoring (gini impurity / entropy) features.

    Warning: If data is too easy, boosting methods is difficult to give score to all features.
    &#34;&#34;&#34;

    def __init__(self,
                 k=None,
                 z_importance_threshold=1.,
                 unbalanced=True,
                 n_cv=5):
        &#34;&#34;&#34;
        Args:
            unbalanced (bool, optional): True to imply class weight to samples. Defaults to False.
        &#34;&#34;&#34;
        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)
        self.unbalanced = unbalanced

        from xgboost import XGBClassifier

        self.kernel = XGBClassifier(random_state=142, subsample=0.7)
        self.name = &#34;XGboost&#34;

    def reference(self) -&gt; dict[str, str]:
        refer = super().reference()
        refer[
            self.name() +
            &#34; document&#34;] = &#34;https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor.feature_importances_&#34;
        return refer

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using XGboost to scoring (gini impurity / entropy) features.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        if self.unbalanced:
            sample_weight = compute_sample_weight(class_weight=&#34;balanced&#34;, y=y)
        else:
            sample_weight = np.ones(len(y))

        y = OneHotEncoder(sparse_output=False).fit_transform(
            y.to_numpy().reshape(-1, 1))
        self.kernel.fit(x, y, sample_weight=sample_weight)
        score = self.kernel.feature_importances_
        scores = pd.Series(score, index=x.columns,
                           name=self.name).sort_values(ascending=False)
        return scores</code></pre>
</details>
<div class="desc"><p>Using XGboost to scoring (gini impurity / entropy) features.</p>
<p>Warning: If data is too easy, boosting methods is difficult to give score to all features.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>unbalanced</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>True to imply class weight to samples. Defaults to False.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="PineBioML.selection.classification.XGboost_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using XGboost to scoring (gini impurity / entropy) features.

    Returns:
        pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
    &#34;&#34;&#34;
    if self.unbalanced:
        sample_weight = compute_sample_weight(class_weight=&#34;balanced&#34;, y=y)
    else:
        sample_weight = np.ones(len(y))

    y = OneHotEncoder(sparse_output=False).fit_transform(
        y.to_numpy().reshape(-1, 1))
    self.kernel.fit(x, y, sample_weight=sample_weight)
    score = self.kernel.feature_importances_
    scores = pd.Series(score, index=x.columns,
                       name=self.name).sort_values(ascending=False)
    return scores</code></pre>
</details>
<div class="desc"><p>Using XGboost to scoring (gini impurity / entropy) features.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>pandas.DataFrame</code></dt>
<dd>The score for each feature. Some elements may be empty.</dd>
</dl></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="PineBioML.selection.classification.ensemble_selector"><code class="flex name class">
<span>class <span class="ident">ensemble_selector</span></span>
<span>(</span><span>k:int=None, z_importance_threshold:float=1.0, n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ensemble_selector(SelectionPipeline):
    &#34;&#34;&#34;
    A functional stack of diffirent methods.    
    What we do here is:    
        1. calculate feature importance in different methods.    
        2. standardize the scores and then averaging through methods.    
        3. If z_importance_threshold not None, then all features with averaging score higher than z_importance_threshold will be selected.    
           else top k feature with averaging score will be selected.    
    &#34;&#34;&#34;

    def __init__(self,
                 k: int = None,
                 z_importance_threshold: float = 1.,
                 n_cv=5):

        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)
        self.name = &#34;ensemble&#34;
        self.kernels = {
            &#34;c45&#34;: DT_selection(k=k, strategy=&#34;c45&#34;, n_cv=n_cv),
            &#34;RF_gini&#34;: RF_selection(k=k, strategy=&#34;gini&#34;, n_cv=n_cv),
            &#34;Lasso&#34;: Lasso_selection(k=k, n_cv=n_cv),
            &#34;multi_Lasso&#34;: multi_Lasso_selection(k=k, n_cv=n_cv),
            &#34;SVM&#34;: SVM_selection(k=k, n_cv=n_cv),

            #&#34;AdaBoost&#34;: AdaBoost_selection(k=k),
            #&#34;XGboost&#34;: XGboost_selection(k=k),
            #&#34;Lightgbm&#34;: Lightgbm_selection(k=k)
        }
        self.n_cv = 1

    def reference(self) -&gt; dict[str, str]:
        refer = super().reference()
        refer[
            self.name() +
            &#34; WARNING&#34;] = &#34;This method has no reference yet. That means the effectivity has not been proven yet. It somehow works in experience.&#34;
        return refer

    def Scoring(self, x, y=None):
        results = []
        for method in self.kernels:
            print(&#34;Using &#34;, method, &#34; to score.&#34;)
            start_time = time.time()

            self.kernels[method].fit(x, y)

            results.append(self.kernels[method].selected_score)
            end_time = time.time()
            print(method,
                  &#34; is done. Using {t:.4f}\n&#34;.format(t=end_time - start_time))

        scores = pd.concat(results, axis=1)
        z_scores = (scores - scores.mean()) / (scores.std() + 1e-4)
        scores[self.name] = z_scores.sum(axis=1)

        return scores

    def Select(self, scores):
        z_scores = scores[self.name].sort_values(ascending=False)

        return super().Select(z_scores)

    def what_matters(self):
        return self.scores

    def Plotting(self):
        for method in self.kernels:
            self.kernels[method].Plotting()</code></pre>
</details>
<div class="desc"><p>A functional stack of diffirent methods.
<br>
What we do here is:
<br>
1. calculate feature importance in different methods.
<br>
2. standardize the scores and then averaging through methods.
<br>
3. If z_importance_threshold not None, then all features with averaging score higher than z_importance_threshold will be selected.
<br>
else top k feature with averaging score will be selected.
</p>
<p>Initialize the selection pipeline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>select top k important feature. k = -1 means selecting all, k = None means selecting the feature that have standarized score &gt; 1. Default = None</dd>
<dt><strong><code>z_importance_threshold</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The threshold to picking features. Defaults to 1.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="PineBioML.selection.classification.ensemble_selector.what_matters"><code class="name flex">
<span>def <span class="ident">what_matters</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def what_matters(self):
    return self.scores</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Scoring" href="index.html#PineBioML.selection.SelectionPipeline.Scoring">Scoring</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="PineBioML.selection.classification.multi_Lasso_selection"><code class="flex name class">
<span>class <span class="ident">multi_Lasso_selection</span></span>
<span>(</span><span>k=None, z_importance_threshold=1.0, n=4, n_cv=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class multi_Lasso_selection(SelectionPipeline):
    &#34;&#34;&#34;
    A stack of Lasso_selection. Because of collinearity, if there are a batch of featres with high corelation, only one of them will remain.    
    That leads to diffirent behavior between select k features in a time and select k//n features in n times.    
    &#34;&#34;&#34;

    def __init__(self, k=None, z_importance_threshold=1., n=4, n_cv=5):
        &#34;&#34;&#34;
        Args:
            n (int , optional): How many times should lasso be performed.    
            objective (str, optional): one of {&#34;Regression&#34;, &#34;BinaryClassification&#34;}
        &#34;&#34;&#34;
        super().__init__(k=k,
                         z_importance_threshold=z_importance_threshold,
                         n_cv=n_cv)
        self.name = &#34;multi_Lasso&#34;
        self.backend = Lasso_selection  #Lasso_bisection_selection
        self.n = n
        self.n_cv = 1  # multi lasso calls lasso which already applied cv

    def reference(self) -&gt; dict[str, str]:
        refer = super().reference()
        refer[
            &#34; Warning&#34;] = &#34;We do not have a reference and this method&#39;s effectivity has not been proven yet.&#34;
        return refer

    def Scoring(self, x, y):
        result = []
        if self.k == -1 or self.k is None:
            self.k = min(x.shape[0], x.shape[1]) // 2
        batch_size = self.k // self.n + 1

        num_selected = 0
        #for i in range(self.n):
        while (num_selected &lt; self.k):
            kernel = self.backend(k=batch_size).fit(x, y)
            result.append(kernel.selected_score)
            batch_selected = result[-1].index
            x = x.drop(batch_selected, axis=1)
            num_selected += len(batch_selected)
            if x.shape[1] == 0:
                break
        result = pd.concat(result).sort_values(ascending=False)
        #result = result - result.min()
        result.name = self.name

        return result</code></pre>
</details>
<div class="desc"><p>A stack of Lasso_selection. Because of collinearity, if there are a batch of featres with high corelation, only one of them will remain.
<br>
That leads to diffirent behavior between select k features in a time and select k//n features in n times.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code> , optional</dt>
<dd>How many times should lasso be performed.
</dd>
<dt><strong><code>objective</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of {"Regression", "BinaryClassification"}</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="PineBioML.selection.SelectionPipeline" href="index.html#PineBioML.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="PineBioML.selection.SelectionPipeline.Plotting" href="index.html#PineBioML.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Report" href="index.html#PineBioML.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Scoring" href="index.html#PineBioML.selection.SelectionPipeline.Scoring">Scoring</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.Select" href="index.html#PineBioML.selection.SelectionPipeline.Select">Select</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.fit" href="index.html#PineBioML.selection.SelectionPipeline.fit">fit</a></code></li>
<li><code><a title="PineBioML.selection.SelectionPipeline.reference" href="index.html#PineBioML.selection.SelectionPipeline.reference">reference</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="PineBioML.selection" href="index.html">PineBioML.selection</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="PineBioML.selection.classification.AdaBoost_selection" href="#PineBioML.selection.classification.AdaBoost_selection">AdaBoost_selection</a></code></h4>
<ul class="">
<li><code><a title="PineBioML.selection.classification.AdaBoost_selection.Scoring" href="#PineBioML.selection.classification.AdaBoost_selection.Scoring">Scoring</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="PineBioML.selection.classification.DT_selection" href="#PineBioML.selection.classification.DT_selection">DT_selection</a></code></h4>
<ul class="">
<li><code><a title="PineBioML.selection.classification.DT_selection.Scoring" href="#PineBioML.selection.classification.DT_selection.Scoring">Scoring</a></code></li>
<li><code><a title="PineBioML.selection.classification.DT_selection.best_splits_c45_batch_optimized" href="#PineBioML.selection.classification.DT_selection.best_splits_c45_batch_optimized">best_splits_c45_batch_optimized</a></code></li>
<li><code><a title="PineBioML.selection.classification.DT_selection.best_splits_gini_batch_optimized" href="#PineBioML.selection.classification.DT_selection.best_splits_gini_batch_optimized">best_splits_gini_batch_optimized</a></code></li>
<li><code><a title="PineBioML.selection.classification.DT_selection.compute_gain_ratio" href="#PineBioML.selection.classification.DT_selection.compute_gain_ratio">compute_gain_ratio</a></code></li>
<li><code><a title="PineBioML.selection.classification.DT_selection.compute_gini" href="#PineBioML.selection.classification.DT_selection.compute_gini">compute_gini</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="PineBioML.selection.classification.Lasso_selection" href="#PineBioML.selection.classification.Lasso_selection">Lasso_selection</a></code></h4>
<ul class="">
<li><code><a title="PineBioML.selection.classification.Lasso_selection.Scoring" href="#PineBioML.selection.classification.Lasso_selection.Scoring">Scoring</a></code></li>
<li><code><a title="PineBioML.selection.classification.Lasso_selection.create_kernel" href="#PineBioML.selection.classification.Lasso_selection.create_kernel">create_kernel</a></code></li>
<li><code><a title="PineBioML.selection.classification.Lasso_selection.plot_coef_1var" href="#PineBioML.selection.classification.Lasso_selection.plot_coef_1var">plot_coef_1var</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="PineBioML.selection.classification.Lightgbm_selection" href="#PineBioML.selection.classification.Lightgbm_selection">Lightgbm_selection</a></code></h4>
<ul class="">
<li><code><a title="PineBioML.selection.classification.Lightgbm_selection.Scoring" href="#PineBioML.selection.classification.Lightgbm_selection.Scoring">Scoring</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="PineBioML.selection.classification.RF_selection" href="#PineBioML.selection.classification.RF_selection">RF_selection</a></code></h4>
<ul class="">
<li><code><a title="PineBioML.selection.classification.RF_selection.Scoring" href="#PineBioML.selection.classification.RF_selection.Scoring">Scoring</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="PineBioML.selection.classification.SVM_selection" href="#PineBioML.selection.classification.SVM_selection">SVM_selection</a></code></h4>
<ul class="">
<li><code><a title="PineBioML.selection.classification.SVM_selection.Scoring" href="#PineBioML.selection.classification.SVM_selection.Scoring">Scoring</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="PineBioML.selection.classification.XGboost_selection" href="#PineBioML.selection.classification.XGboost_selection">XGboost_selection</a></code></h4>
<ul class="">
<li><code><a title="PineBioML.selection.classification.XGboost_selection.Scoring" href="#PineBioML.selection.classification.XGboost_selection.Scoring">Scoring</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="PineBioML.selection.classification.ensemble_selector" href="#PineBioML.selection.classification.ensemble_selector">ensemble_selector</a></code></h4>
<ul class="">
<li><code><a title="PineBioML.selection.classification.ensemble_selector.what_matters" href="#PineBioML.selection.classification.ensemble_selector.what_matters">what_matters</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="PineBioML.selection.classification.multi_Lasso_selection" href="#PineBioML.selection.classification.multi_Lasso_selection">multi_Lasso_selection</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
