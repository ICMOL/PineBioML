<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>package.selection.RF API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>package.selection.RF</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from . import SelectionPipeline
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from sklearn.utils import shuffle
from sklearn.tree import DecisionTreeClassifier
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss


class RF_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Using random forest to scoring (gini impurity / entropy) features.

    &#34;&#34;&#34;

    def __init__(self,
                 trees=1024 * 16,
                 unbalanced=True,
                 strategy=&#34;gini&#34;,
                 center=True,
                 scale=True):
        &#34;&#34;&#34;
        Args:
            trees (int, optional): Number of trees. Defaults to 1024*16.
            strategy (str, optional): Scoring strategy, one of {&#34;gini&#34;, &#34;entropy&#34;}. Defaults to &#34;gini&#34;.
            unbalanced (bool, optional): True to imply class weight to samples. Defaults to True.
            center (bool, optional): Pass to Normalizer. Defaults to True.
            scale (bool, optional): Pass to Normalizer. Defaults to True.
        &#34;&#34;&#34;
        super().__init__(center=center, scale=scale)
        self.strategy = strategy
        if unbalanced:
            class_weight = &#34;balanced&#34;
        else:
            class_weight = None

        self.kernel = RandomForestClassifier(n_estimators=trees,
                                             n_jobs=-1,
                                             max_samples=0.75,
                                             class_weight=class_weight,
                                             criterion=strategy,
                                             verbose=1,
                                             ccp_alpha=1e-2)
        self.name = &#34;RandomForest_&#34; + self.strategy

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using random forest to scoring (gini impurity / entropy) features.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods. Defaults to None.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        self.kernel.fit(x, y)
        score = self.kernel.feature_importances_
        self.scores = pd.Series(score, index=x.columns,
                                name=self.name).sort_values(ascending=False)
        return self.scores.copy()


class oob_RFClassifier:
    &#34;&#34;&#34; 
    A random forest implement with out-of-bag evaluation. Boostrap subsampling strategy using Bernoulli sampling.
    &#34;&#34;&#34;

    def __init__(self, trees=1024 * 8, unbalanced=True):
        &#34;&#34;&#34;
        Args:
            trees (int, optional): Number of trees. Defaults to 1024*16.
            unbalanced (bool, optional): True to imply class weight to samples. Defaults to True.
        
        To do:
            Now is only for classification.
        &#34;&#34;&#34;
        if unbalanced:
            class_weight = &#34;balanced&#34;
        else:
            class_weight = None
        self.subsampling_ratio = 0.7
        self.n_trees = trees
        self.tree_parms = {
            &#34;criterion&#34;: &#34;gini&#34;,
            &#34;splitter&#34;: &#39;best&#39;,
            &#34;max_depth&#34;: None,
            &#34;min_samples_split&#34;: 2,
            &#34;min_samples_leaf&#34;: 1,
            &#34;min_weight_fraction_leaf&#34;: 0.0,
            &#34;max_features&#34;: &#34;sqrt&#34;,
            &#34;class_weight&#34;: class_weight,
            &#34;ccp_alpha&#34;: 1e-2
        }
        self.trees = {}

    def fit(self, x, y):
        &#34;&#34;&#34;
        Training the random forest.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods.
        &#34;&#34;&#34;
        self.subsampling_table = pd.DataFrame(np.random.binomial(
            1, self.subsampling_ratio,
            size=(x.shape[0], self.n_trees)).astype(np.bool_),
                                              index=x.index)
        for i_th in tqdm(self.subsampling_table.columns):
            subsample = self.subsampling_table[i_th]
            sub_x = x.loc[subsample]
            sub_y = y.loc[subsample]

            self.trees[i_th] = DecisionTreeClassifier(**self.tree_parms).fit(
                sub_x, sub_y)

    def predict_prob(self, x):
        &#34;&#34;&#34;
        Give a ratio that how many trees in the forest predict x as positive.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.

        Returns:
            pandas.Series or a 1D array: ratio that how many trees in the forest predict x as positive. Defaults to None.
        &#34;&#34;&#34;
        return pd.Series([t.predict(x) for t in self.trees.items],
                         index=x.index,
                         name=&#34;RF_prob&#34;).mean(axis=1)

    def oob_predict_prob(self, x):
        &#34;&#34;&#34;
        x must be the training data.
        
        Give a ratio that how many trees from forest predict out-of-bag x as positive.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.

        Returns:
            pandas.Series or a 1D array: ratio that how many trees from forest predict out-of-bag x as positive. Defaults to None.
        &#34;&#34;&#34;
        if len(x) == len(self.subsampling_table):
            if not (x.index == self.subsampling_table.index).all():
                print(
                    &#34;oob_predict_prob detect input x which diffirs from training&#34;
                )
        else:
            print(
                &#34;oob_predict_prob detect input x which diffirs from training&#34;)

        predicts = pd.Series([t.predict(x) for t in self.trees.items],
                             index=x.index,
                             name=&#34;RF_prob&#34;).divide
        oob_mask = np.logical_not(self.subsampling_table)
        predicts = predicts * oob_mask

        return predicts.sum(axis=1) / oob_mask.sum(axis=1)

    def evaluate(self, x, y, metric=&#34;ACC&#34;, oob=False):
        &#34;&#34;&#34;
        Evaluate model using input x, y

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods.
            metric (str, optional): One of {acc, f1, bce, auc}. Defaults to &#34;ACC&#34;.
            oob (bool, optional): True to use out of bag evaluate. Defaults to False.

        Returns:
            float: Evaluation result
        &#34;&#34;&#34;
        if oob:
            y_pred = self.oob_predict_prob(x)
        else:
            y_pred = self.predict_prob(x)

        if metric in [&#34;ACC&#34;, &#34;acc&#34;, &#34;accuracy&#34;]:
            return accuracy_score(y, y_pred &gt; 0.5)
        elif metric in [&#34;f1&#34;, &#34;F1&#34;, &#34;f1_score&#34;, &#34;F1_score&#34;]:
            return f1_score(y, y_pred &gt; 0.5)
        elif metric in [&#34;BCE&#34;, &#34;bce&#34;, &#34;cross_entropy&#34;, &#34;log_loss&#34;]:
            return log_loss(y, y_pred)
        elif metric in [&#34;AUC&#34;, &#34;auc&#34;, &#34;roc_auc&#34;, &#34;ROC_AUC&#34;]:
            return roc_auc_score(y, y_pred)
        else:
            print(&#34;Metric &#34;, metric,
                  &#34; not support! Please use one of acc, f1, bce or roc_auc.&#34;)
            return 0


class pcRF_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Expiriment method. PCA-&gt;RF-&gt;importance-&gt;inverse_PCA
    &#34;&#34;&#34;

    def __init__(self,
                 trees=512,
                 unbalanced=True,
                 strategy=&#34;permutation&#34;,
                 factorize_method=&#34;PCA&#34;,
                 center=True,
                 scale=True):
        &#34;&#34;&#34;
        Args:
            trees (int, optional): Number of trees. Defaults to 512.
            unbalanced (bool, optional): _description_. Defaults to True.
            strategy (str, optional): Scoring strategy, one of {&#34;gini&#34;, &#34;entropy&#34;, &#34;permutation&#34;}. Defaults to &#34;permutation&#34;.
            factorize_method (str, optional): One of {&#34;PCA&#34;}. Method to reduce dimension.  Defaults to &#34;PCA&#34;.
            center (bool, optional): Pass to Normalizer. Defaults to True.
            scale (bool, optional): Pass to Normalizer. Defaults to True.
                    
        &#34;&#34;&#34;
        super().__init__(center=center, scale=scale)
        # remove colinearity
        #        if factorize_method == &#34;NMF&#34;:
        #           self.fatorizer = NMF()
        #      else:
        #   self.fatorizer = PCA()

        if unbalanced:
            class_weight = &#34;balanced&#34;
        else:
            class_weight = None

        self.strategy = strategy
        #self.kernel = RandomForestClassifier(n_estimators = trees, bootstrap=True, oob_score=True, n_jobs=-1, class_weight = class_weight, verbose = 1)
        self.kernel = oob_RFClassifier(trees)
        self.name = &#34;pcRandomForest_&#34; + self.strategy

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using random forest to scoring (gini impurity / entropy) principal components.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods. Defaults to None.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        print(&#34;pc RF kernel fitting.&#34;)
        self.kernel.fit(x, y)

        n_repeat = 5
        print(&#34;Permutation evaluation start! n_repeat: &#34;, n_repeat)
        score = pd.DataFrame(0,
                             index=x.columns,
                             columns=[i for i in range(n_repeat)])
        for i in range(n_repeat):  # repeat 5 times
            print(&#34;    repeat: &#34;, i)
            for col in tqdm(x.columns):  # permutate each column
                x_permute = x.copy()
                x_permute.loc[:, col] = shuffle(x_permute[col]).values
                score.loc[col, i] = self.kernel.evaluate(x_permute,
                                                         y,
                                                         oob=True)

        score = score.mean(axis=1)

        return score

    def Select(self, x, y, k):
        &#34;&#34;&#34;
        x-&gt;PCA-&gt;RF + oob +permutation importance -&gt; inverse PCA -&gt; feature importance

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods. Defaults to None.
            k (int): Number of feature to select. The result may less than k

        Returns:
            pandas.Series: The score for k selected features. May less than k.
        &#34;&#34;&#34;

        # x should be a pd dataframe or a numpy array without missing value
        x, y = self.normalizer.fit_transform(x, y)
        columns = x.columns
        index = x.index

        # remove colinearity
        # tune number of factor
        tmpca = PCA()
        pc_x = tmpca.fit_transform(x)
        accumucate_evr = 0
        threshold = 0.95
        i = 0
        for evr in tmpca.explained_variance_ratio_:
            accumucate_evr += evr
            i += 1
            if accumucate_evr &gt; threshold:
                break
        self.n_pc = i

        # do the decomposition
        self.factorizer = PCA(self.n_pc)
        pc_x = pd.DataFrame(self.factorizer.fit_transform(x), index=index)

        # scoring
        pc_scores = self.scoring(pc_x, y)

        # revert importance of pricipal component to importance of feature via ratio of variance
        self.scores = pd.Series(
            pc_scores.dot(
                np.abs(self.factorizer.components_ *
                       self.factorizer.explained_variance_ratio_.reshape(
                           self.n_pc, 1))),  #
            index=columns,
            name=self.name).sort_values(ascending=False)

        selected_score = self.choose(self.scores, k)
        return selected_score</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="package.selection.RF.RF_selection"><code class="flex name class">
<span>class <span class="ident">RF_selection</span></span>
<span>(</span><span>trees=16384, unbalanced=True, strategy='gini', center=True, scale=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Using random forest to scoring (gini impurity / entropy) features.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>trees</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trees. Defaults to 1024*16.</dd>
<dt><strong><code>strategy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Scoring strategy, one of {"gini", "entropy"}. Defaults to "gini".</dd>
<dt><strong><code>unbalanced</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>True to imply class weight to samples. Defaults to True.</dd>
<dt><strong><code>center</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Pass to Normalizer. Defaults to True.</dd>
<dt><strong><code>scale</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Pass to Normalizer. Defaults to True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RF_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Using random forest to scoring (gini impurity / entropy) features.

    &#34;&#34;&#34;

    def __init__(self,
                 trees=1024 * 16,
                 unbalanced=True,
                 strategy=&#34;gini&#34;,
                 center=True,
                 scale=True):
        &#34;&#34;&#34;
        Args:
            trees (int, optional): Number of trees. Defaults to 1024*16.
            strategy (str, optional): Scoring strategy, one of {&#34;gini&#34;, &#34;entropy&#34;}. Defaults to &#34;gini&#34;.
            unbalanced (bool, optional): True to imply class weight to samples. Defaults to True.
            center (bool, optional): Pass to Normalizer. Defaults to True.
            scale (bool, optional): Pass to Normalizer. Defaults to True.
        &#34;&#34;&#34;
        super().__init__(center=center, scale=scale)
        self.strategy = strategy
        if unbalanced:
            class_weight = &#34;balanced&#34;
        else:
            class_weight = None

        self.kernel = RandomForestClassifier(n_estimators=trees,
                                             n_jobs=-1,
                                             max_samples=0.75,
                                             class_weight=class_weight,
                                             criterion=strategy,
                                             verbose=1,
                                             ccp_alpha=1e-2)
        self.name = &#34;RandomForest_&#34; + self.strategy

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using random forest to scoring (gini impurity / entropy) features.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods. Defaults to None.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        self.kernel.fit(x, y)
        score = self.kernel.feature_importances_
        self.scores = pd.Series(score, index=x.columns,
                                name=self.name).sort_values(ascending=False)
        return self.scores.copy()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="package.selection.SelectionPipeline" href="index.html#package.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="package.selection.RF.RF_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Using random forest to scoring (gini impurity / entropy) features.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>a 2D array</code></dt>
<dd>The data to extract information.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pandas.Series</code> or <code>a 1D array</code></dt>
<dd>The target label for methods. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>pandas.DataFrame</code></dt>
<dd>The score for each feature. Some elements may be empty.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using random forest to scoring (gini impurity / entropy) features.

    Args:
        x (pandas.DataFrame or a 2D array): The data to extract information.
        y (pandas.Series or a 1D array): The target label for methods. Defaults to None.

    Returns:
        pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
    &#34;&#34;&#34;
    self.kernel.fit(x, y)
    score = self.kernel.feature_importances_
    self.scores = pd.Series(score, index=x.columns,
                            name=self.name).sort_values(ascending=False)
    return self.scores.copy()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="package.selection.SelectionPipeline" href="index.html#package.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="package.selection.SelectionPipeline.Choose" href="index.html#package.selection.SelectionPipeline.Choose">Choose</a></code></li>
<li><code><a title="package.selection.SelectionPipeline.Diagnose" href="index.html#package.selection.SelectionPipeline.Diagnose">Diagnose</a></code></li>
<li><code><a title="package.selection.SelectionPipeline.Plotting" href="index.html#package.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="package.selection.SelectionPipeline.Report" href="index.html#package.selection.SelectionPipeline.Report">Report</a></code></li>
<li><code><a title="package.selection.SelectionPipeline.Select" href="index.html#package.selection.SelectionPipeline.Select">Select</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="package.selection.RF.oob_RFClassifier"><code class="flex name class">
<span>class <span class="ident">oob_RFClassifier</span></span>
<span>(</span><span>trees=8192, unbalanced=True)</span>
</code></dt>
<dd>
<div class="desc"><p>A random forest implement with out-of-bag evaluation. Boostrap subsampling strategy using Bernoulli sampling.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>trees</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trees. Defaults to 1024*16.</dd>
<dt><strong><code>unbalanced</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>True to imply class weight to samples. Defaults to True.</dd>
</dl>
<p>To do:
Now is only for classification.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class oob_RFClassifier:
    &#34;&#34;&#34; 
    A random forest implement with out-of-bag evaluation. Boostrap subsampling strategy using Bernoulli sampling.
    &#34;&#34;&#34;

    def __init__(self, trees=1024 * 8, unbalanced=True):
        &#34;&#34;&#34;
        Args:
            trees (int, optional): Number of trees. Defaults to 1024*16.
            unbalanced (bool, optional): True to imply class weight to samples. Defaults to True.
        
        To do:
            Now is only for classification.
        &#34;&#34;&#34;
        if unbalanced:
            class_weight = &#34;balanced&#34;
        else:
            class_weight = None
        self.subsampling_ratio = 0.7
        self.n_trees = trees
        self.tree_parms = {
            &#34;criterion&#34;: &#34;gini&#34;,
            &#34;splitter&#34;: &#39;best&#39;,
            &#34;max_depth&#34;: None,
            &#34;min_samples_split&#34;: 2,
            &#34;min_samples_leaf&#34;: 1,
            &#34;min_weight_fraction_leaf&#34;: 0.0,
            &#34;max_features&#34;: &#34;sqrt&#34;,
            &#34;class_weight&#34;: class_weight,
            &#34;ccp_alpha&#34;: 1e-2
        }
        self.trees = {}

    def fit(self, x, y):
        &#34;&#34;&#34;
        Training the random forest.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods.
        &#34;&#34;&#34;
        self.subsampling_table = pd.DataFrame(np.random.binomial(
            1, self.subsampling_ratio,
            size=(x.shape[0], self.n_trees)).astype(np.bool_),
                                              index=x.index)
        for i_th in tqdm(self.subsampling_table.columns):
            subsample = self.subsampling_table[i_th]
            sub_x = x.loc[subsample]
            sub_y = y.loc[subsample]

            self.trees[i_th] = DecisionTreeClassifier(**self.tree_parms).fit(
                sub_x, sub_y)

    def predict_prob(self, x):
        &#34;&#34;&#34;
        Give a ratio that how many trees in the forest predict x as positive.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.

        Returns:
            pandas.Series or a 1D array: ratio that how many trees in the forest predict x as positive. Defaults to None.
        &#34;&#34;&#34;
        return pd.Series([t.predict(x) for t in self.trees.items],
                         index=x.index,
                         name=&#34;RF_prob&#34;).mean(axis=1)

    def oob_predict_prob(self, x):
        &#34;&#34;&#34;
        x must be the training data.
        
        Give a ratio that how many trees from forest predict out-of-bag x as positive.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.

        Returns:
            pandas.Series or a 1D array: ratio that how many trees from forest predict out-of-bag x as positive. Defaults to None.
        &#34;&#34;&#34;
        if len(x) == len(self.subsampling_table):
            if not (x.index == self.subsampling_table.index).all():
                print(
                    &#34;oob_predict_prob detect input x which diffirs from training&#34;
                )
        else:
            print(
                &#34;oob_predict_prob detect input x which diffirs from training&#34;)

        predicts = pd.Series([t.predict(x) for t in self.trees.items],
                             index=x.index,
                             name=&#34;RF_prob&#34;).divide
        oob_mask = np.logical_not(self.subsampling_table)
        predicts = predicts * oob_mask

        return predicts.sum(axis=1) / oob_mask.sum(axis=1)

    def evaluate(self, x, y, metric=&#34;ACC&#34;, oob=False):
        &#34;&#34;&#34;
        Evaluate model using input x, y

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods.
            metric (str, optional): One of {acc, f1, bce, auc}. Defaults to &#34;ACC&#34;.
            oob (bool, optional): True to use out of bag evaluate. Defaults to False.

        Returns:
            float: Evaluation result
        &#34;&#34;&#34;
        if oob:
            y_pred = self.oob_predict_prob(x)
        else:
            y_pred = self.predict_prob(x)

        if metric in [&#34;ACC&#34;, &#34;acc&#34;, &#34;accuracy&#34;]:
            return accuracy_score(y, y_pred &gt; 0.5)
        elif metric in [&#34;f1&#34;, &#34;F1&#34;, &#34;f1_score&#34;, &#34;F1_score&#34;]:
            return f1_score(y, y_pred &gt; 0.5)
        elif metric in [&#34;BCE&#34;, &#34;bce&#34;, &#34;cross_entropy&#34;, &#34;log_loss&#34;]:
            return log_loss(y, y_pred)
        elif metric in [&#34;AUC&#34;, &#34;auc&#34;, &#34;roc_auc&#34;, &#34;ROC_AUC&#34;]:
            return roc_auc_score(y, y_pred)
        else:
            print(&#34;Metric &#34;, metric,
                  &#34; not support! Please use one of acc, f1, bce or roc_auc.&#34;)
            return 0</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="package.selection.RF.oob_RFClassifier.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, x, y, metric='ACC', oob=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate model using input x, y</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>a 2D array</code></dt>
<dd>The data to extract information.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pandas.Series</code> or <code>a 1D array</code></dt>
<dd>The target label for methods.</dd>
<dt><strong><code>metric</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>One of {acc, f1, bce, auc}. Defaults to "ACC".</dd>
<dt><strong><code>oob</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>True to use out of bag evaluate. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>Evaluation result</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, x, y, metric=&#34;ACC&#34;, oob=False):
    &#34;&#34;&#34;
    Evaluate model using input x, y

    Args:
        x (pandas.DataFrame or a 2D array): The data to extract information.
        y (pandas.Series or a 1D array): The target label for methods.
        metric (str, optional): One of {acc, f1, bce, auc}. Defaults to &#34;ACC&#34;.
        oob (bool, optional): True to use out of bag evaluate. Defaults to False.

    Returns:
        float: Evaluation result
    &#34;&#34;&#34;
    if oob:
        y_pred = self.oob_predict_prob(x)
    else:
        y_pred = self.predict_prob(x)

    if metric in [&#34;ACC&#34;, &#34;acc&#34;, &#34;accuracy&#34;]:
        return accuracy_score(y, y_pred &gt; 0.5)
    elif metric in [&#34;f1&#34;, &#34;F1&#34;, &#34;f1_score&#34;, &#34;F1_score&#34;]:
        return f1_score(y, y_pred &gt; 0.5)
    elif metric in [&#34;BCE&#34;, &#34;bce&#34;, &#34;cross_entropy&#34;, &#34;log_loss&#34;]:
        return log_loss(y, y_pred)
    elif metric in [&#34;AUC&#34;, &#34;auc&#34;, &#34;roc_auc&#34;, &#34;ROC_AUC&#34;]:
        return roc_auc_score(y, y_pred)
    else:
        print(&#34;Metric &#34;, metric,
              &#34; not support! Please use one of acc, f1, bce or roc_auc.&#34;)
        return 0</code></pre>
</details>
</dd>
<dt id="package.selection.RF.oob_RFClassifier.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, x, y)</span>
</code></dt>
<dd>
<div class="desc"><p>Training the random forest.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>a 2D array</code></dt>
<dd>The data to extract information.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pandas.Series</code> or <code>a 1D array</code></dt>
<dd>The target label for methods.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, x, y):
    &#34;&#34;&#34;
    Training the random forest.

    Args:
        x (pandas.DataFrame or a 2D array): The data to extract information.
        y (pandas.Series or a 1D array): The target label for methods.
    &#34;&#34;&#34;
    self.subsampling_table = pd.DataFrame(np.random.binomial(
        1, self.subsampling_ratio,
        size=(x.shape[0], self.n_trees)).astype(np.bool_),
                                          index=x.index)
    for i_th in tqdm(self.subsampling_table.columns):
        subsample = self.subsampling_table[i_th]
        sub_x = x.loc[subsample]
        sub_y = y.loc[subsample]

        self.trees[i_th] = DecisionTreeClassifier(**self.tree_parms).fit(
            sub_x, sub_y)</code></pre>
</details>
</dd>
<dt id="package.selection.RF.oob_RFClassifier.oob_predict_prob"><code class="name flex">
<span>def <span class="ident">oob_predict_prob</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>x must be the training data.</p>
<p>Give a ratio that how many trees from forest predict out-of-bag x as positive.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>a 2D array</code></dt>
<dd>The data to extract information.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>a 1D array</code></dt>
<dd>ratio that how many trees from forest predict out-of-bag x as positive. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oob_predict_prob(self, x):
    &#34;&#34;&#34;
    x must be the training data.
    
    Give a ratio that how many trees from forest predict out-of-bag x as positive.

    Args:
        x (pandas.DataFrame or a 2D array): The data to extract information.

    Returns:
        pandas.Series or a 1D array: ratio that how many trees from forest predict out-of-bag x as positive. Defaults to None.
    &#34;&#34;&#34;
    if len(x) == len(self.subsampling_table):
        if not (x.index == self.subsampling_table.index).all():
            print(
                &#34;oob_predict_prob detect input x which diffirs from training&#34;
            )
    else:
        print(
            &#34;oob_predict_prob detect input x which diffirs from training&#34;)

    predicts = pd.Series([t.predict(x) for t in self.trees.items],
                         index=x.index,
                         name=&#34;RF_prob&#34;).divide
    oob_mask = np.logical_not(self.subsampling_table)
    predicts = predicts * oob_mask

    return predicts.sum(axis=1) / oob_mask.sum(axis=1)</code></pre>
</details>
</dd>
<dt id="package.selection.RF.oob_RFClassifier.predict_prob"><code class="name flex">
<span>def <span class="ident">predict_prob</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Give a ratio that how many trees in the forest predict x as positive.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>a 2D array</code></dt>
<dd>The data to extract information.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>a 1D array</code></dt>
<dd>ratio that how many trees in the forest predict x as positive. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_prob(self, x):
    &#34;&#34;&#34;
    Give a ratio that how many trees in the forest predict x as positive.

    Args:
        x (pandas.DataFrame or a 2D array): The data to extract information.

    Returns:
        pandas.Series or a 1D array: ratio that how many trees in the forest predict x as positive. Defaults to None.
    &#34;&#34;&#34;
    return pd.Series([t.predict(x) for t in self.trees.items],
                     index=x.index,
                     name=&#34;RF_prob&#34;).mean(axis=1)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="package.selection.RF.pcRF_selection"><code class="flex name class">
<span>class <span class="ident">pcRF_selection</span></span>
<span>(</span><span>trees=512, unbalanced=True, strategy='permutation', factorize_method='PCA', center=True, scale=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Expiriment method. PCA-&gt;RF-&gt;importance-&gt;inverse_PCA</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>trees</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trees. Defaults to 512.</dd>
<dt><strong><code>unbalanced</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd><em>description</em>. Defaults to True.</dd>
<dt><strong><code>strategy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Scoring strategy, one of {"gini", "entropy", "permutation"}. Defaults to "permutation".</dd>
<dt><strong><code>factorize_method</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>One of {"PCA"}. Method to reduce dimension.
Defaults to "PCA".</dd>
<dt><strong><code>center</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Pass to Normalizer. Defaults to True.</dd>
<dt><strong><code>scale</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Pass to Normalizer. Defaults to True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class pcRF_selection(SelectionPipeline):
    &#34;&#34;&#34;
    Expiriment method. PCA-&gt;RF-&gt;importance-&gt;inverse_PCA
    &#34;&#34;&#34;

    def __init__(self,
                 trees=512,
                 unbalanced=True,
                 strategy=&#34;permutation&#34;,
                 factorize_method=&#34;PCA&#34;,
                 center=True,
                 scale=True):
        &#34;&#34;&#34;
        Args:
            trees (int, optional): Number of trees. Defaults to 512.
            unbalanced (bool, optional): _description_. Defaults to True.
            strategy (str, optional): Scoring strategy, one of {&#34;gini&#34;, &#34;entropy&#34;, &#34;permutation&#34;}. Defaults to &#34;permutation&#34;.
            factorize_method (str, optional): One of {&#34;PCA&#34;}. Method to reduce dimension.  Defaults to &#34;PCA&#34;.
            center (bool, optional): Pass to Normalizer. Defaults to True.
            scale (bool, optional): Pass to Normalizer. Defaults to True.
                    
        &#34;&#34;&#34;
        super().__init__(center=center, scale=scale)
        # remove colinearity
        #        if factorize_method == &#34;NMF&#34;:
        #           self.fatorizer = NMF()
        #      else:
        #   self.fatorizer = PCA()

        if unbalanced:
            class_weight = &#34;balanced&#34;
        else:
            class_weight = None

        self.strategy = strategy
        #self.kernel = RandomForestClassifier(n_estimators = trees, bootstrap=True, oob_score=True, n_jobs=-1, class_weight = class_weight, verbose = 1)
        self.kernel = oob_RFClassifier(trees)
        self.name = &#34;pcRandomForest_&#34; + self.strategy

    def Scoring(self, x, y=None):
        &#34;&#34;&#34;
        Using random forest to scoring (gini impurity / entropy) principal components.

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods. Defaults to None.

        Returns:
            pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
        &#34;&#34;&#34;
        print(&#34;pc RF kernel fitting.&#34;)
        self.kernel.fit(x, y)

        n_repeat = 5
        print(&#34;Permutation evaluation start! n_repeat: &#34;, n_repeat)
        score = pd.DataFrame(0,
                             index=x.columns,
                             columns=[i for i in range(n_repeat)])
        for i in range(n_repeat):  # repeat 5 times
            print(&#34;    repeat: &#34;, i)
            for col in tqdm(x.columns):  # permutate each column
                x_permute = x.copy()
                x_permute.loc[:, col] = shuffle(x_permute[col]).values
                score.loc[col, i] = self.kernel.evaluate(x_permute,
                                                         y,
                                                         oob=True)

        score = score.mean(axis=1)

        return score

    def Select(self, x, y, k):
        &#34;&#34;&#34;
        x-&gt;PCA-&gt;RF + oob +permutation importance -&gt; inverse PCA -&gt; feature importance

        Args:
            x (pandas.DataFrame or a 2D array): The data to extract information.
            y (pandas.Series or a 1D array): The target label for methods. Defaults to None.
            k (int): Number of feature to select. The result may less than k

        Returns:
            pandas.Series: The score for k selected features. May less than k.
        &#34;&#34;&#34;

        # x should be a pd dataframe or a numpy array without missing value
        x, y = self.normalizer.fit_transform(x, y)
        columns = x.columns
        index = x.index

        # remove colinearity
        # tune number of factor
        tmpca = PCA()
        pc_x = tmpca.fit_transform(x)
        accumucate_evr = 0
        threshold = 0.95
        i = 0
        for evr in tmpca.explained_variance_ratio_:
            accumucate_evr += evr
            i += 1
            if accumucate_evr &gt; threshold:
                break
        self.n_pc = i

        # do the decomposition
        self.factorizer = PCA(self.n_pc)
        pc_x = pd.DataFrame(self.factorizer.fit_transform(x), index=index)

        # scoring
        pc_scores = self.scoring(pc_x, y)

        # revert importance of pricipal component to importance of feature via ratio of variance
        self.scores = pd.Series(
            pc_scores.dot(
                np.abs(self.factorizer.components_ *
                       self.factorizer.explained_variance_ratio_.reshape(
                           self.n_pc, 1))),  #
            index=columns,
            name=self.name).sort_values(ascending=False)

        selected_score = self.choose(self.scores, k)
        return selected_score</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="package.selection.SelectionPipeline" href="index.html#package.selection.SelectionPipeline">SelectionPipeline</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="package.selection.RF.pcRF_selection.Scoring"><code class="name flex">
<span>def <span class="ident">Scoring</span></span>(<span>self, x, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Using random forest to scoring (gini impurity / entropy) principal components.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>a 2D array</code></dt>
<dd>The data to extract information.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pandas.Series</code> or <code>a 1D array</code></dt>
<dd>The target label for methods. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code> or <code>pandas.DataFrame</code></dt>
<dd>The score for each feature. Some elements may be empty.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Scoring(self, x, y=None):
    &#34;&#34;&#34;
    Using random forest to scoring (gini impurity / entropy) principal components.

    Args:
        x (pandas.DataFrame or a 2D array): The data to extract information.
        y (pandas.Series or a 1D array): The target label for methods. Defaults to None.

    Returns:
        pandas.Series or pandas.DataFrame: The score for each feature. Some elements may be empty.
    &#34;&#34;&#34;
    print(&#34;pc RF kernel fitting.&#34;)
    self.kernel.fit(x, y)

    n_repeat = 5
    print(&#34;Permutation evaluation start! n_repeat: &#34;, n_repeat)
    score = pd.DataFrame(0,
                         index=x.columns,
                         columns=[i for i in range(n_repeat)])
    for i in range(n_repeat):  # repeat 5 times
        print(&#34;    repeat: &#34;, i)
        for col in tqdm(x.columns):  # permutate each column
            x_permute = x.copy()
            x_permute.loc[:, col] = shuffle(x_permute[col]).values
            score.loc[col, i] = self.kernel.evaluate(x_permute,
                                                     y,
                                                     oob=True)

    score = score.mean(axis=1)

    return score</code></pre>
</details>
</dd>
<dt id="package.selection.RF.pcRF_selection.Select"><code class="name flex">
<span>def <span class="ident">Select</span></span>(<span>self, x, y, k)</span>
</code></dt>
<dd>
<div class="desc"><p>x-&gt;PCA-&gt;RF + oob +permutation importance -&gt; inverse PCA -&gt; feature importance</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>a 2D array</code></dt>
<dd>The data to extract information.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pandas.Series</code> or <code>a 1D array</code></dt>
<dd>The target label for methods. Defaults to None.</dd>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of feature to select. The result may less than k</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.Series</code></dt>
<dd>The score for k selected features. May less than k.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Select(self, x, y, k):
    &#34;&#34;&#34;
    x-&gt;PCA-&gt;RF + oob +permutation importance -&gt; inverse PCA -&gt; feature importance

    Args:
        x (pandas.DataFrame or a 2D array): The data to extract information.
        y (pandas.Series or a 1D array): The target label for methods. Defaults to None.
        k (int): Number of feature to select. The result may less than k

    Returns:
        pandas.Series: The score for k selected features. May less than k.
    &#34;&#34;&#34;

    # x should be a pd dataframe or a numpy array without missing value
    x, y = self.normalizer.fit_transform(x, y)
    columns = x.columns
    index = x.index

    # remove colinearity
    # tune number of factor
    tmpca = PCA()
    pc_x = tmpca.fit_transform(x)
    accumucate_evr = 0
    threshold = 0.95
    i = 0
    for evr in tmpca.explained_variance_ratio_:
        accumucate_evr += evr
        i += 1
        if accumucate_evr &gt; threshold:
            break
    self.n_pc = i

    # do the decomposition
    self.factorizer = PCA(self.n_pc)
    pc_x = pd.DataFrame(self.factorizer.fit_transform(x), index=index)

    # scoring
    pc_scores = self.scoring(pc_x, y)

    # revert importance of pricipal component to importance of feature via ratio of variance
    self.scores = pd.Series(
        pc_scores.dot(
            np.abs(self.factorizer.components_ *
                   self.factorizer.explained_variance_ratio_.reshape(
                       self.n_pc, 1))),  #
        index=columns,
        name=self.name).sort_values(ascending=False)

    selected_score = self.choose(self.scores, k)
    return selected_score</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="package.selection.SelectionPipeline" href="index.html#package.selection.SelectionPipeline">SelectionPipeline</a></b></code>:
<ul class="hlist">
<li><code><a title="package.selection.SelectionPipeline.Choose" href="index.html#package.selection.SelectionPipeline.Choose">Choose</a></code></li>
<li><code><a title="package.selection.SelectionPipeline.Diagnose" href="index.html#package.selection.SelectionPipeline.Diagnose">Diagnose</a></code></li>
<li><code><a title="package.selection.SelectionPipeline.Plotting" href="index.html#package.selection.SelectionPipeline.Plotting">Plotting</a></code></li>
<li><code><a title="package.selection.SelectionPipeline.Report" href="index.html#package.selection.SelectionPipeline.Report">Report</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="package.selection" href="index.html">package.selection</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="package.selection.RF.RF_selection" href="#package.selection.RF.RF_selection">RF_selection</a></code></h4>
<ul class="">
<li><code><a title="package.selection.RF.RF_selection.Scoring" href="#package.selection.RF.RF_selection.Scoring">Scoring</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="package.selection.RF.oob_RFClassifier" href="#package.selection.RF.oob_RFClassifier">oob_RFClassifier</a></code></h4>
<ul class="">
<li><code><a title="package.selection.RF.oob_RFClassifier.evaluate" href="#package.selection.RF.oob_RFClassifier.evaluate">evaluate</a></code></li>
<li><code><a title="package.selection.RF.oob_RFClassifier.fit" href="#package.selection.RF.oob_RFClassifier.fit">fit</a></code></li>
<li><code><a title="package.selection.RF.oob_RFClassifier.oob_predict_prob" href="#package.selection.RF.oob_RFClassifier.oob_predict_prob">oob_predict_prob</a></code></li>
<li><code><a title="package.selection.RF.oob_RFClassifier.predict_prob" href="#package.selection.RF.oob_RFClassifier.predict_prob">predict_prob</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="package.selection.RF.pcRF_selection" href="#package.selection.RF.pcRF_selection">pcRF_selection</a></code></h4>
<ul class="">
<li><code><a title="package.selection.RF.pcRF_selection.Scoring" href="#package.selection.RF.pcRF_selection.Scoring">Scoring</a></code></li>
<li><code><a title="package.selection.RF.pcRF_selection.Select" href="#package.selection.RF.pcRF_selection.Select">Select</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>