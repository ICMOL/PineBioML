{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e345685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4676ad0",
   "metadata": {},
   "source": [
    "# IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2412dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PineBioML.preprocessing import IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be66d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "input_folder = \"./input/\"\n",
    "output_folder = \"./output/\"\n",
    "export_title = \"example_basic \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8435813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = IO.read_multiple_groups(\n",
    "    file_path_list=[\n",
    "        input_folder+ \"example_group1.csv\", # all samples from this file will have y = 0, because it is in the 1st place of the file path list.\n",
    "        input_folder+ \"example_group2.tsv\", # all samples from this file will have y = 1, because it is in the 2nd place of the file path list.\n",
    "    ],\n",
    "    index_col=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2888b70",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ddc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.33, random_state=142, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67931f0",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7df5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PineBioML.preprocessing import Normalizer, Pass\n",
    "from PineBioML.preprocessing.impute import knn_imputer, simple_imputer\n",
    "from PineBioML.preprocessing.utils import feature_extension\n",
    "from PineBioML.selection.ensemble import selector\n",
    "from PineBioML.model.supervised import Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# define the experiment pipeline\n",
    "experiment = [\n",
    "    (\"MissingValueProcessing\", {\n",
    "        \"mean\": simple_imputer(threshold=1., strategy=\"mean\")\n",
    "        }),\n",
    "    (\"Standarization\", {\n",
    "        \"PowerTransformer\": Normalizer(method=\"PowerTransformer\"), \n",
    "        \"StandardScaler\": Normalizer(method=\"StandardScaler\"),\n",
    "        }),\n",
    "    (\"FeatureExpansion\", {\n",
    "        \"PCA * /\": feature_extension(), \n",
    "        \"None\": Pass()\n",
    "        }),\n",
    "    (\"Selection\", {\n",
    "        \"ensemble\":selector(RF_trees=256, z_importance_threshold = 1), \n",
    "        \"None\": Pass()\n",
    "        }),\n",
    "    (\"Modeling\", {\n",
    "        \"LgisticRegression\": LogisticRegression(penalty = None),\n",
    "        \"ElasticNetLogisticRegression\": Classification.ElasticLogit_tuner(target = \"roc_auc\", validate_penalty=True),\n",
    "        \"rbf-SVM\": Classification.SVM_tuner(target=\"f1\", validate_penalty=True),\n",
    "        \"DecisionTree\": Classification.DecisionTree_tuner(target=\"neg_log_loss\", validate_penalty=True),\n",
    "        \"RandomForest\": Classification.RandomForest_tuner(validate_penalty=True),\n",
    "        \"AdaBoost\": Classification.AdaBoost_tuner(target=\"recall\", validate_penalty=True),\n",
    "        \"XGBoost\": Classification.XGBoost_tuner(validate_penalty=True),\n",
    "        \"LightGBM\": Classification.LighGBM_tuner(validate_penalty=True),\n",
    "        }),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0615f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  c45  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:00<00:00, 440.04it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c45  is done.\n",
      "\n",
      "Using  RF_gini  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 256 out of 256 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_gini  is done.\n",
      "\n",
      "Using  AdaBoost  to select.\n",
      "I don't have a progress bar but I am running\n",
      "AdaBoost  is done.\n",
      "\n",
      "Using  Lasso_Bisection  to select.\n",
      "Lasso_Bisection  is done.\n",
      "\n",
      "Using  multi_Lasso  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.233e-02, tolerance: 3.350e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.941e-02, tolerance: 3.350e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_Lasso  is done.\n",
      "\n",
      "Using  SVM  to select.\n",
      "SVM  is done.\n",
      "\n",
      "Using  XGboost  to select.\n",
      "XGboost  is done.\n",
      "\n",
      "Using  Lightgbm  to select.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 67, number of negative: 67\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7324\n",
      "[LightGBM] [Info] Number of data points in the train set: 134, number of used features: 158\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Lightgbm  is done.\n",
      "\n",
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  18\n",
      "LogisticRegression(C=95.0981955951379, class_weight='balanced',\n",
      "                   l1_ratio=0.7992130894511869, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n",
      "optuna seed 71  |  validation seed 6961  |  model seed 16086\n",
      "    start tuning. it will take a while.\n",
      "    default is better.\n",
      "SVC(probability=True, random_state=16086) \n",
      "\n",
      "optuna seed 71  |  validation seed 11518  |  model seed 3950\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  21\n",
      "DecisionTreeClassifier(ccp_alpha=0.05686687547066959, class_weight='balanced',\n",
      "                       max_depth=11, min_samples_leaf=2, min_samples_split=5,\n",
      "                       random_state=426) \n",
      "\n",
      "optuna seed 71  |  validation seed 7524  |  model seed 15028\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  34\n",
      "RandomForestClassifier(ccp_alpha=0.006160002459451302, class_weight='balanced',\n",
      "                       max_depth=3, max_samples=0.7555385953218438,\n",
      "                       min_samples_leaf=15, n_estimators=82, n_jobs=-1,\n",
      "                       oob_score=True, random_state=7125) \n",
      "\n",
      "optuna seed 71  |  validation seed 4062  |  model seed 15363\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  48\n",
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.060655582116147515,\n",
      "                   n_estimators=15, random_state=12937) \n",
      "\n",
      "optuna seed 71  |  validation seed 5704  |  model seed 10374\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  116\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5817021406494164, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=3.458039200335059,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.403188518148714,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=62, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=2851, ...) \n",
      "\n",
      "optuna seed 71  |  validation seed 14625  |  model seed 7610\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  183\n",
      "LGBMClassifier(class_weight='balanced', learning_rate=0.02098064942306669,\n",
      "               max_depth=10, min_child_samples=26, n_estimators=47,\n",
      "               num_leaves=264, random_state=4302, reg_lambda=9.734382399805362,\n",
      "               subsample_freq=1, verbosity=-1) \n",
      "\n",
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optuna is better, best trial:  18\n",
      "LogisticRegression(C=0.061873055013445755, class_weight='balanced',\n",
      "                   l1_ratio=0.7825270021085338, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n",
      "optuna seed 71  |  validation seed 6961  |  model seed 16086\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  23\n",
      "SVC(C=158.34873413470524, class_weight='balanced', gamma='auto',\n",
      "    probability=True, random_state=8485) \n",
      "\n",
      "optuna seed 71  |  validation seed 11518  |  model seed 3950\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  21\n",
      "DecisionTreeClassifier(ccp_alpha=0.06995430392280887, class_weight='balanced',\n",
      "                       max_depth=4, min_samples_split=11, random_state=426) \n",
      "\n",
      "optuna seed 71  |  validation seed 7524  |  model seed 15028\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  24\n",
      "RandomForestClassifier(ccp_alpha=0.007757638040232419, class_weight='balanced',\n",
      "                       max_depth=3, max_samples=0.8545903564246629,\n",
      "                       min_samples_leaf=7, n_estimators=42, n_jobs=-1,\n",
      "                       oob_score=True, random_state=13711) \n",
      "\n",
      "optuna seed 71  |  validation seed 4062  |  model seed 15363\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  23\n",
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.026617445656963164,\n",
      "                   n_estimators=74, random_state=1896) \n",
      "\n",
      "optuna seed 71  |  validation seed 5704  |  model seed 10374\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  121\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=11.466913031335647, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3732802836504629,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=215, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=14288, ...) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna seed 71  |  validation seed 14625  |  model seed 7610\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  170\n",
      "LGBMClassifier(class_weight='balanced', learning_rate=0.010042777658280091,\n",
      "               max_depth=3, min_child_samples=25, n_estimators=32, num_leaves=4,\n",
      "               random_state=6661, reg_lambda=0.6007555063677047,\n",
      "               subsample_freq=1, verbosity=-1) \n",
      "\n",
      "Using  c45  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 194.64it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c45  is done.\n",
      "\n",
      "Using  RF_gini  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 256 out of 256 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_gini  is done.\n",
      "\n",
      "Using  AdaBoost  to select.\n",
      "I don't have a progress bar but I am running\n",
      "AdaBoost  is done.\n",
      "\n",
      "Using  Lasso_Bisection  to select.\n",
      "Lasso_Bisection  is done.\n",
      "\n",
      "Using  multi_Lasso  to select.\n",
      "multi_Lasso  is done.\n",
      "\n",
      "Using  SVM  to select.\n",
      "SVM  is done.\n",
      "\n",
      "Using  XGboost  to select.\n",
      "XGboost  is done.\n",
      "\n",
      "Using  Lightgbm  to select.\n",
      "[LightGBM] [Info] Number of positive: 67, number of negative: 67\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4642\n",
      "[LightGBM] [Info] Number of data points in the train set: 134, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Lightgbm  is done.\n",
      "\n",
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  18\n",
      "LogisticRegression(C=95.0981955951379, class_weight='balanced',\n",
      "                   l1_ratio=0.7992130894511869, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n",
      "optuna seed 71  |  validation seed 6961  |  model seed 16086\n",
      "    start tuning. it will take a while.\n",
      "    default is better.\n",
      "SVC(probability=True, random_state=16086) \n",
      "\n",
      "optuna seed 71  |  validation seed 11518  |  model seed 3950\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  21\n",
      "DecisionTreeClassifier(ccp_alpha=0.05686687547066959, class_weight='balanced',\n",
      "                       max_depth=11, min_samples_leaf=2, min_samples_split=5,\n",
      "                       random_state=426) \n",
      "\n",
      "optuna seed 71  |  validation seed 7524  |  model seed 15028\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  34\n",
      "RandomForestClassifier(ccp_alpha=0.006160002459451302, class_weight='balanced',\n",
      "                       max_depth=3, max_samples=0.7555385953218438,\n",
      "                       min_samples_leaf=15, n_estimators=82, n_jobs=-1,\n",
      "                       oob_score=True, random_state=7125) \n",
      "\n",
      "optuna seed 71  |  validation seed 4062  |  model seed 15363\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  48\n",
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.060655582116147515,\n",
      "                   n_estimators=15, random_state=12937) \n",
      "\n",
      "optuna seed 71  |  validation seed 5704  |  model seed 10374\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  116\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5817021406494164, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=3.458039200335059,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.403188518148714,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=62, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=2851, ...) \n",
      "\n",
      "optuna seed 71  |  validation seed 14625  |  model seed 7610\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  183\n",
      "LGBMClassifier(class_weight='balanced', learning_rate=0.02098064942306669,\n",
      "               max_depth=10, min_child_samples=26, n_estimators=47,\n",
      "               num_leaves=264, random_state=4302, reg_lambda=9.734382399805362,\n",
      "               subsample_freq=1, verbosity=-1) \n",
      "\n",
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optuna is better, best trial:  11\n",
      "LogisticRegression(C=0.08251132513486935, class_weight='balanced',\n",
      "                   l1_ratio=0.998619178844397, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n",
      "optuna seed 71  |  validation seed 6961  |  model seed 16086\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  23\n",
      "SVC(C=200.20758695186146, class_weight='balanced', gamma='auto',\n",
      "    probability=True, random_state=8485) \n",
      "\n",
      "optuna seed 71  |  validation seed 11518  |  model seed 3950\n",
      "    start tuning. it will take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optuna is better, best trial:  21\n",
      "DecisionTreeClassifier(ccp_alpha=0.07011005949801337, class_weight='balanced',\n",
      "                       max_depth=6, min_samples_leaf=2, min_samples_split=13,\n",
      "                       random_state=426) \n",
      "\n",
      "optuna seed 71  |  validation seed 7524  |  model seed 15028\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  49\n",
      "RandomForestClassifier(ccp_alpha=0.009044145660486839, class_weight='balanced',\n",
      "                       max_depth=14, max_samples=0.7704135143194771,\n",
      "                       min_samples_leaf=5, n_estimators=292, n_jobs=-1,\n",
      "                       oob_score=True, random_state=6864) \n",
      "\n",
      "optuna seed 71  |  validation seed 4062  |  model seed 15363\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  14\n",
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.01809899102431482,\n",
      "                   n_estimators=29, random_state=1376) \n",
      "\n",
      "optuna seed 71  |  validation seed 5704  |  model seed 10374\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  151\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=12.509626775971661, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.10598004133286405,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=277, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=15801, ...) \n",
      "\n",
      "optuna seed 71  |  validation seed 14625  |  model seed 7610\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  177\n",
      "LGBMClassifier(class_weight='balanced', learning_rate=0.2246172437282419,\n",
      "               max_depth=10, min_child_samples=27, n_estimators=18,\n",
      "               num_leaves=401, random_state=15076, reg_lambda=5.141490064720642,\n",
      "               subsample_freq=1, verbosity=-1) \n",
      "\n",
      "Using  c45  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:00<00:00, 204.24it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c45  is done.\n",
      "\n",
      "Using  RF_gini  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 256 out of 256 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_gini  is done.\n",
      "\n",
      "Using  AdaBoost  to select.\n",
      "I don't have a progress bar but I am running\n",
      "AdaBoost  is done.\n",
      "\n",
      "Using  Lasso_Bisection  to select.\n",
      "Lasso_Bisection  is done.\n",
      "\n",
      "Using  multi_Lasso  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e-02, tolerance: 3.350e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.002e-02, tolerance: 3.350e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_Lasso  is done.\n",
      "\n",
      "Using  SVM  to select.\n",
      "SVM  is done.\n",
      "\n",
      "Using  XGboost  to select.\n",
      "XGboost  is done.\n",
      "\n",
      "Using  Lightgbm  to select.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 67, number of negative: 67\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7320\n",
      "[LightGBM] [Info] Number of data points in the train set: 134, number of used features: 158\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Lightgbm  is done.\n",
      "\n",
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  22\n",
      "LogisticRegression(C=9.140919782073336, class_weight='balanced',\n",
      "                   l1_ratio=0.13871810012304295, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n",
      "optuna seed 71  |  validation seed 6961  |  model seed 16086\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  10\n",
      "SVC(C=0.5457919384642952, class_weight='balanced', gamma='auto',\n",
      "    probability=True, random_state=11885) \n",
      "\n",
      "optuna seed 71  |  validation seed 11518  |  model seed 3950\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  21\n",
      "DecisionTreeClassifier(ccp_alpha=0.05686687547066959, class_weight='balanced',\n",
      "                       max_depth=11, min_samples_leaf=2, min_samples_split=5,\n",
      "                       random_state=426) \n",
      "\n",
      "optuna seed 71  |  validation seed 7524  |  model seed 15028\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  34\n",
      "RandomForestClassifier(ccp_alpha=0.01736402935889676, class_weight='balanced',\n",
      "                       max_depth=8, max_samples=0.6951056793509277,\n",
      "                       min_samples_leaf=13, n_estimators=365, n_jobs=-1,\n",
      "                       oob_score=True, random_state=7125) \n",
      "\n",
      "optuna seed 71  |  validation seed 4062  |  model seed 15363\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  48\n",
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.060655582116147515,\n",
      "                   n_estimators=15, random_state=12937) \n",
      "\n",
      "optuna seed 71  |  validation seed 5704  |  model seed 10374\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  61\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=3.0693277558001015, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1524986959682761,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=29, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=13300, ...) \n",
      "\n",
      "optuna seed 71  |  validation seed 14625  |  model seed 7610\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  107\n",
      "LGBMClassifier(class_weight='balanced', learning_rate=0.017896594533881018,\n",
      "               max_depth=13, min_child_samples=21, n_estimators=42,\n",
      "               num_leaves=2704, random_state=9182,\n",
      "               reg_lambda=0.2493808814811177, subsample_freq=1, verbosity=-1) \n",
      "\n",
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optuna is better, best trial:  12\n",
      "LogisticRegression(C=0.06506794622985379, class_weight='balanced',\n",
      "                   l1_ratio=0.806112924730366, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n",
      "optuna seed 71  |  validation seed 6961  |  model seed 16086\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  23\n",
      "SVC(C=240.73139798892663, class_weight='balanced', gamma='auto',\n",
      "    probability=True, random_state=8485) \n",
      "\n",
      "optuna seed 71  |  validation seed 11518  |  model seed 3950\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  21\n",
      "DecisionTreeClassifier(ccp_alpha=0.06995430392280887, class_weight='balanced',\n",
      "                       max_depth=4, min_samples_split=11, random_state=426) \n",
      "\n",
      "optuna seed 71  |  validation seed 7524  |  model seed 15028\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  37\n",
      "RandomForestClassifier(ccp_alpha=0.014265930139097917, class_weight='balanced',\n",
      "                       max_depth=3, max_samples=0.8070233242371828,\n",
      "                       min_samples_leaf=5, n_estimators=53, n_jobs=-1,\n",
      "                       oob_score=True, random_state=14843) \n",
      "\n",
      "optuna seed 71  |  validation seed 4062  |  model seed 15363\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  14\n",
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.01809899102431482,\n",
      "                   n_estimators=29, random_state=1376) \n",
      "\n",
      "optuna seed 71  |  validation seed 5704  |  model seed 10374\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  39\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=7.907657625198003, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2634992617086981,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=197, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=10695, ...) \n",
      "\n",
      "optuna seed 71  |  validation seed 14625  |  model seed 7610\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  142\n",
      "LGBMClassifier(class_weight='balanced', learning_rate=0.01080772656667565,\n",
      "               max_depth=15, min_child_samples=25, n_estimators=23,\n",
      "               num_leaves=2692, random_state=4611,\n",
      "               reg_lambda=0.011359742942048766, subsample_freq=1, verbosity=-1) \n",
      "\n",
      "Using  c45  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 202.39it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c45  is done.\n",
      "\n",
      "Using  RF_gini  to select.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 256 out of 256 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_gini  is done.\n",
      "\n",
      "Using  AdaBoost  to select.\n",
      "I don't have a progress bar but I am running\n",
      "AdaBoost  is done.\n",
      "\n",
      "Using  Lasso_Bisection  to select.\n",
      "Lasso_Bisection  is done.\n",
      "\n",
      "Using  multi_Lasso  to select.\n",
      "multi_Lasso  is done.\n",
      "\n",
      "Using  SVM  to select.\n",
      "SVM  is done.\n",
      "\n",
      "Using  XGboost  to select.\n",
      "XGboost  is done.\n",
      "\n",
      "Using  Lightgbm  to select.\n",
      "[LightGBM] [Info] Number of positive: 67, number of negative: 67\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4640\n",
      "[LightGBM] [Info] Number of data points in the train set: 134, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Lightgbm  is done.\n",
      "\n",
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  18\n",
      "LogisticRegression(C=92.62959230496637, class_weight='balanced',\n",
      "                   l1_ratio=0.47516189402343534, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n",
      "optuna seed 71  |  validation seed 6961  |  model seed 16086\n",
      "    start tuning. it will take a while.\n",
      "    default is better.\n",
      "SVC(probability=True, random_state=16086) \n",
      "\n",
      "optuna seed 71  |  validation seed 11518  |  model seed 3950\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  21\n",
      "DecisionTreeClassifier(ccp_alpha=0.05686687547066959, class_weight='balanced',\n",
      "                       max_depth=11, min_samples_leaf=2, min_samples_split=5,\n",
      "                       random_state=426) \n",
      "\n",
      "optuna seed 71  |  validation seed 7524  |  model seed 15028\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  34\n",
      "RandomForestClassifier(ccp_alpha=0.006160002459451302, class_weight='balanced',\n",
      "                       max_depth=3, max_samples=0.7555385953218438,\n",
      "                       min_samples_leaf=15, n_estimators=82, n_jobs=-1,\n",
      "                       oob_score=True, random_state=7125) \n",
      "\n",
      "optuna seed 71  |  validation seed 4062  |  model seed 15363\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  48\n",
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.060655582116147515,\n",
      "                   n_estimators=15, random_state=12937) \n",
      "\n",
      "optuna seed 71  |  validation seed 5704  |  model seed 10374\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  116\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5817021406494164, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=3.458039200335059,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.403188518148714,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=62, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=2851, ...) \n",
      "\n",
      "optuna seed 71  |  validation seed 14625  |  model seed 7610\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  185\n",
      "LGBMClassifier(class_weight='balanced', learning_rate=0.010897638636770153,\n",
      "               max_depth=8, min_child_samples=23, n_estimators=40,\n",
      "               num_leaves=84, random_state=4609, reg_lambda=5.501285225853382,\n",
      "               subsample_freq=1, verbosity=-1) \n",
      "\n",
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optuna is better, best trial:  11\n",
      "LogisticRegression(C=0.08251132513486935, class_weight='balanced',\n",
      "                   l1_ratio=0.998619178844397, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n",
      "optuna seed 71  |  validation seed 6961  |  model seed 16086\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  23\n",
      "SVC(C=137.11886709323161, class_weight='balanced', gamma='auto',\n",
      "    probability=True, random_state=8485) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna seed 71  |  validation seed 11518  |  model seed 3950\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  21\n",
      "DecisionTreeClassifier(ccp_alpha=0.07011005949801337, class_weight='balanced',\n",
      "                       max_depth=6, min_samples_leaf=2, min_samples_split=13,\n",
      "                       random_state=426) \n",
      "\n",
      "optuna seed 71  |  validation seed 7524  |  model seed 15028\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  49\n",
      "RandomForestClassifier(ccp_alpha=0.009044145660486839, class_weight='balanced',\n",
      "                       max_depth=14, max_samples=0.7704135143194771,\n",
      "                       min_samples_leaf=5, n_estimators=292, n_jobs=-1,\n",
      "                       oob_score=True, random_state=6864) \n",
      "\n",
      "optuna seed 71  |  validation seed 4062  |  model seed 15363\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  14\n",
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.01809899102431482,\n",
      "                   n_estimators=29, random_state=1376) \n",
      "\n",
      "optuna seed 71  |  validation seed 5704  |  model seed 10374\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  151\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=12.509626775971661, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.10598004133286405,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=277, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=15801, ...) \n",
      "\n",
      "optuna seed 71  |  validation seed 14625  |  model seed 7610\n",
      "    start tuning. it will take a while.\n",
      "    optuna is better, best trial:  195\n",
      "LGBMClassifier(class_weight='balanced', learning_rate=0.01206173398029653,\n",
      "               max_depth=11, min_child_samples=24, n_estimators=35,\n",
      "               num_leaves=1852, random_state=12851,\n",
      "               reg_lambda=1.4483557009368562, subsample_freq=1, verbosity=-1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PineBioML.model.utils import Pine\n",
    "\n",
    "pine_automl = Pine(experiment)\n",
    "result = pine_automl.do_experiment(x_train, y_train, x_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b8ff5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MissingValueProcessing</th>\n",
       "      <th>Standarization</th>\n",
       "      <th>FeatureExpansion</th>\n",
       "      <th>Selection</th>\n",
       "      <th>Modeling</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1-score</th>\n",
       "      <th>train_support</th>\n",
       "      <th>train_sensitivity</th>\n",
       "      <th>...</th>\n",
       "      <th>cv_mcc</th>\n",
       "      <th>cv_auc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1-score</th>\n",
       "      <th>test_support</th>\n",
       "      <th>test_sensitivity</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>LgisticRegression</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385680</td>\n",
       "      <td>0.751479</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.349780</td>\n",
       "      <td>0.718090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>ElasticNetLogisticRegression</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385680</td>\n",
       "      <td>0.750380</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.349780</td>\n",
       "      <td>0.718090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>rbf-SVM</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319484</td>\n",
       "      <td>0.754269</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0.641873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208855</td>\n",
       "      <td>0.608791</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.476290</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393780</td>\n",
       "      <td>0.731023</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.274753</td>\n",
       "      <td>0.722681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288859</td>\n",
       "      <td>0.621429</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.476290</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221145</td>\n",
       "      <td>0.557819</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.245256</td>\n",
       "      <td>0.685950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310246</td>\n",
       "      <td>0.636264</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.365902</td>\n",
       "      <td>0.713499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316139</td>\n",
       "      <td>0.662637</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.476290</td>\n",
       "      <td>0.682277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373579</td>\n",
       "      <td>0.730473</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.343582</td>\n",
       "      <td>0.670340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MissingValueProcessing    Standarization FeatureExpansion Selection  \\\n",
       "0                    mean  PowerTransformer          PCA * /  ensemble   \n",
       "1                    mean  PowerTransformer          PCA * /  ensemble   \n",
       "2                    mean  PowerTransformer          PCA * /  ensemble   \n",
       "3                    mean  PowerTransformer          PCA * /  ensemble   \n",
       "4                    mean  PowerTransformer          PCA * /  ensemble   \n",
       "..                    ...               ...              ...       ...   \n",
       "59                   mean    StandardScaler             None      None   \n",
       "60                   mean    StandardScaler             None      None   \n",
       "61                   mean    StandardScaler             None      None   \n",
       "62                   mean    StandardScaler             None      None   \n",
       "63                   mean    StandardScaler             None      None   \n",
       "\n",
       "                        Modeling  train_precision  train_recall  \\\n",
       "0              LgisticRegression         0.710145      0.731343   \n",
       "1   ElasticNetLogisticRegression         0.710145      0.731343   \n",
       "2                        rbf-SVM         0.737705      0.671642   \n",
       "3                   DecisionTree         0.622449      0.910448   \n",
       "4                   RandomForest         0.762712      0.671642   \n",
       "..                           ...              ...           ...   \n",
       "59                  DecisionTree         0.622449      0.910448   \n",
       "60                  RandomForest         1.000000      1.000000   \n",
       "61                      AdaBoost         0.589286      0.985075   \n",
       "62                       XGBoost         0.622449      0.910448   \n",
       "63                      LightGBM         0.820896      0.820896   \n",
       "\n",
       "    train_f1-score  train_support  train_sensitivity  ...    cv_mcc    cv_auc  \\\n",
       "0         0.720588           67.0           0.731343  ...  0.385680  0.751479   \n",
       "1         0.720588           67.0           0.731343  ...  0.385680  0.750380   \n",
       "2         0.703125           67.0           0.671642  ...  0.319484  0.754269   \n",
       "3         0.739394           67.0           0.910448  ...  0.208855  0.608791   \n",
       "4         0.714286           67.0           0.671642  ...  0.393780  0.731023   \n",
       "..             ...            ...                ...  ...       ...       ...   \n",
       "59        0.739394           67.0           0.910448  ...  0.288859  0.621429   \n",
       "60        1.000000           67.0           1.000000  ...  0.221145  0.557819   \n",
       "61        0.737430           67.0           0.985075  ...  0.310246  0.636264   \n",
       "62        0.739394           67.0           0.910448  ...  0.316139  0.662637   \n",
       "63        0.820896           67.0           0.820896  ...  0.373579  0.730473   \n",
       "\n",
       "    test_precision  test_recall  test_f1-score  test_support  \\\n",
       "0         0.627907     0.818182       0.710526          33.0   \n",
       "1         0.627907     0.818182       0.710526          33.0   \n",
       "2         0.600000     0.727273       0.657534          33.0   \n",
       "3         0.645833     0.939394       0.765432          33.0   \n",
       "4         0.621622     0.696970       0.657143          33.0   \n",
       "..             ...          ...            ...           ...   \n",
       "59        0.645833     0.939394       0.765432          33.0   \n",
       "60        0.605263     0.696970       0.647887          33.0   \n",
       "61        0.581818     0.969697       0.727273          33.0   \n",
       "62        0.645833     0.939394       0.765432          33.0   \n",
       "63        0.634146     0.787879       0.702703          33.0   \n",
       "\n",
       "    test_sensitivity  test_specificity  test_mcc  test_auc  \n",
       "0           0.818182          0.515152  0.349780  0.718090  \n",
       "1           0.818182          0.515152  0.349780  0.718090  \n",
       "2           0.727273          0.515152  0.248069  0.641873  \n",
       "3           0.939394          0.484848  0.476290  0.712121  \n",
       "4           0.696970          0.575758  0.274753  0.722681  \n",
       "..               ...               ...       ...       ...  \n",
       "59          0.939394          0.484848  0.476290  0.712121  \n",
       "60          0.696970          0.545455  0.245256  0.685950  \n",
       "61          0.969697          0.303030  0.365902  0.713499  \n",
       "62          0.939394          0.484848  0.476290  0.682277  \n",
       "63          0.787879          0.545455  0.343582  0.670340  \n",
       "\n",
       "[64 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the results\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c0dfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MissingValueProcessing</th>\n",
       "      <th>Standarization</th>\n",
       "      <th>FeatureExpansion</th>\n",
       "      <th>Selection</th>\n",
       "      <th>Modeling</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1-score</th>\n",
       "      <th>train_support</th>\n",
       "      <th>train_sensitivity</th>\n",
       "      <th>...</th>\n",
       "      <th>cv_mcc</th>\n",
       "      <th>cv_auc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1-score</th>\n",
       "      <th>test_support</th>\n",
       "      <th>test_sensitivity</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>None</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016085</td>\n",
       "      <td>0.506509</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.274753</td>\n",
       "      <td>0.564738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>None</td>\n",
       "      <td>rbf-SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097306</td>\n",
       "      <td>0.547591</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.121716</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>None</td>\n",
       "      <td>rbf-SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125363</td>\n",
       "      <td>0.546238</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.121716</td>\n",
       "      <td>0.624426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>rbf-SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092098</td>\n",
       "      <td>0.576162</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.181902</td>\n",
       "      <td>0.629017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>rbf-SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092098</td>\n",
       "      <td>0.569569</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.629017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>None</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.970149</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.970149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157018</td>\n",
       "      <td>0.626881</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490511</td>\n",
       "      <td>0.750230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>None</td>\n",
       "      <td>ElasticNetLogisticRegression</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299361</td>\n",
       "      <td>0.711074</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490511</td>\n",
       "      <td>0.796143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>PCA * /</td>\n",
       "      <td>None</td>\n",
       "      <td>ElasticNetLogisticRegression</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258858</td>\n",
       "      <td>0.690110</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.523884</td>\n",
       "      <td>0.796143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mean</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ElasticNetLogisticRegression</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251696</td>\n",
       "      <td>0.707439</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.462250</td>\n",
       "      <td>0.797062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>mean</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ElasticNetLogisticRegression</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267726</td>\n",
       "      <td>0.708538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.440959</td>\n",
       "      <td>0.804408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MissingValueProcessing    Standarization FeatureExpansion Selection  \\\n",
       "44                   mean    StandardScaler          PCA * /      None   \n",
       "42                   mean    StandardScaler          PCA * /      None   \n",
       "10                   mean  PowerTransformer          PCA * /      None   \n",
       "26                   mean  PowerTransformer             None      None   \n",
       "58                   mean    StandardScaler             None      None   \n",
       "..                    ...               ...              ...       ...   \n",
       "12                   mean  PowerTransformer          PCA * /      None   \n",
       "9                    mean  PowerTransformer          PCA * /      None   \n",
       "41                   mean    StandardScaler          PCA * /      None   \n",
       "25                   mean  PowerTransformer             None      None   \n",
       "57                   mean    StandardScaler             None      None   \n",
       "\n",
       "                        Modeling  train_precision  train_recall  \\\n",
       "44                  RandomForest         0.970588      0.985075   \n",
       "42                       rbf-SVM         1.000000      1.000000   \n",
       "10                       rbf-SVM         1.000000      1.000000   \n",
       "26                       rbf-SVM         1.000000      1.000000   \n",
       "58                       rbf-SVM         1.000000      1.000000   \n",
       "..                           ...              ...           ...   \n",
       "12                  RandomForest         0.928571      0.970149   \n",
       "9   ElasticNetLogisticRegression         0.656716      0.656716   \n",
       "41  ElasticNetLogisticRegression         0.661972      0.701493   \n",
       "25  ElasticNetLogisticRegression         0.657143      0.686567   \n",
       "57  ElasticNetLogisticRegression         0.666667      0.716418   \n",
       "\n",
       "    train_f1-score  train_support  train_sensitivity  ...    cv_mcc    cv_auc  \\\n",
       "44        0.977778           67.0           0.985075  ... -0.016085  0.506509   \n",
       "42        1.000000           67.0           1.000000  ...  0.097306  0.547591   \n",
       "10        1.000000           67.0           1.000000  ...  0.125363  0.546238   \n",
       "26        1.000000           67.0           1.000000  ...  0.092098  0.576162   \n",
       "58        1.000000           67.0           1.000000  ...  0.092098  0.569569   \n",
       "..             ...            ...                ...  ...       ...       ...   \n",
       "12        0.948905           67.0           0.970149  ...  0.157018  0.626881   \n",
       "9         0.656716           67.0           0.656716  ...  0.299361  0.711074   \n",
       "41        0.681159           67.0           0.701493  ...  0.258858  0.690110   \n",
       "25        0.671533           67.0           0.686567  ...  0.251696  0.707439   \n",
       "57        0.690647           67.0           0.716418  ...  0.267726  0.708538   \n",
       "\n",
       "    test_precision  test_recall  test_f1-score  test_support  \\\n",
       "44        0.621622     0.696970       0.657143          33.0   \n",
       "42        0.478261     0.333333       0.392857          33.0   \n",
       "10        0.541667     0.393939       0.456140          33.0   \n",
       "26        0.520000     0.393939       0.448276          33.0   \n",
       "58        0.586207     0.515152       0.548387          33.0   \n",
       "..             ...          ...            ...           ...   \n",
       "12        0.710526     0.818182       0.760563          33.0   \n",
       "9         0.710526     0.818182       0.760563          33.0   \n",
       "41        0.717949     0.848485       0.777778          33.0   \n",
       "25        0.692308     0.818182       0.750000          33.0   \n",
       "57        0.666667     0.848485       0.746667          33.0   \n",
       "\n",
       "    test_sensitivity  test_specificity  test_mcc  test_auc  \n",
       "44          0.696970          0.575758  0.274753  0.564738  \n",
       "42          0.333333          0.636364  0.121716  0.619835  \n",
       "10          0.393939          0.666667  0.121716  0.624426  \n",
       "26          0.393939          0.636364  0.181902  0.629017  \n",
       "58          0.515152          0.636364  0.151515  0.629017  \n",
       "..               ...               ...       ...       ...  \n",
       "12          0.818182          0.666667  0.490511  0.750230  \n",
       "9           0.818182          0.666667  0.490511  0.796143  \n",
       "41          0.848485          0.666667  0.523884  0.796143  \n",
       "25          0.818182          0.636364  0.462250  0.797062  \n",
       "57          0.848485          0.575758  0.440959  0.804408  \n",
       "\n",
       "[64 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort according to test_auc\n",
    "result.sort_values(\"test_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092b032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "result.to_csv(\"./output/example_Pine_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b69d2",
   "metadata": {},
   "source": [
    "# Pick a model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77792284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that the model is not fitted yet\n",
    "model = pine_automl.recall_model(id = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec856fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna seed 71  |  validation seed 13694  |  model seed 7398\n",
      "    start tuning. it will take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optuna is better, best trial:  18\n",
      "LogisticRegression(C=0.061873055013445755, class_weight='balanced',\n",
      "                   l1_ratio=0.7825270021085338, penalty='elasticnet',\n",
      "                   solver='saga') \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\aimhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(x_train, y_train)\n",
    "y_valid_prob = model.predict_proba(x_valid)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b18f7f",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3de0d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.67      0.72        33\n",
      "         1.0       0.71      0.82      0.76        33\n",
      "\n",
      "    accuracy                           0.74        66\n",
      "   macro avg       0.75      0.74      0.74        66\n",
      "weighted avg       0.75      0.74      0.74        66\n",
      "\n",
      "sensitivity: 0.818\n",
      "specificity: 0.667\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABhjklEQVR4nO3deZyN5f/H8dfMmBUziFloGPuSfQ2VkmgTaZnspKRsmZQlaxESkSWyk75IKkWEENJmS9ZsUcwwyQyDGebcvz/un6PJjOaMM3Ofc+b9fDzOo7mvc9/nfI6D3q7rvq7LyzAMAxERERFxe95WFyAiIiIizqFgJyIiIuIhFOxEREREPISCnYiIiIiHULATERER8RAKdiIiIiIeQsFORERExEMo2ImIiIh4CAU7EREREQ+hYCciIiLiIRTsRMQlHTt2DC8vL/vD29ubQoUK8dBDD7F169YMr9uyZQuPP/44YWFh+Pv7ExUVxQsvvMDx48czvGbnzp20a9eOyMhI/P39KVSoEE2aNGHOnDmkpqZmx8cTEckWXtorVkRc0bFjxyhZsiStW7fm4YcfJjU1lYMHDzJ16lQuXbrETz/9RJUqVdJcM2nSJHr37k2pUqXo1KkTERER7Nu3j5kzZwKwcuVKGjRokOaamTNn0q1bN8LCwmjfvj1ly5bl/PnzrFu3jhUrVjBixAgGDhyYY59bRORWKNiJiEu6FuzGjh1L37597e2rVq3ioYce4sUXX2Tq1Kn29i1btnDPPffQsGFDVq1aRVBQkP25w4cP07BhQ7y9vdmzZw8FCxYE4Pvvv+euu+6ifv36rFy5kvz586ep4eeff+bXX3+lU6dO2fthb+Ly5cv4+fnh7a0BFhH5b/qbQkTcyt133w2YYe2f3nzzTby8vJg3b16aUAdQunRp3n77bU6dOsX06dPt7cOHD8fLy4uFCxfeEOoAateunalQ99VXX9GoUSPy589PcHAwderU4aOPPrI/HxUVle7r3Hvvvdx777324w0bNuDl5cWiRYsYNGgQxYoVIygoiO3bt9s/27+tXr0aLy8vvvzyS3vbn3/+ybPPPmsfjr7jjjuYPXv2f34OEXF/CnYi4laOHTsGYO91A7h48SLr1q3j7rvvpmTJkuleFx0djb+/vz0AXbvmnnvuoXjx4lmuZ+7cuTzyyCOcPXuWAQMGMHr0aKpXr86qVauy/JpvvvkmK1asoG/fvrz11ltUqlSJUqVKsWTJkhvOXbx4MQULFqRZs2YAxMXFceedd7J27Vp69OjBxIkTKVOmDF26dGHChAlZrklE3EMeqwsQEbmZixcvEh8fT2pqKr/99hsxMTEAPPnkk/ZzfvvtN65evUq1atUyfB1/f3/Kly/Pvn37ADh06BBXrly54T49RyQkJNCrVy/q1q3Lhg0bCAgIsD93K3e5XL58mZ9//pnAwEB7W3R0NO+88w5///23PdSmpKTw6aef0qpVK3x9fQF4/fXXSU1NZffu3dx2220AdOvWjdatWzNs2DBeeOGFNK8rIp5FPXYi4tKGDh1KkSJFCA8P5+6772bfvn2MGzcuTbA7f/48QLrDqf+UP39+EhMTAez//a9rbmbNmjWcP3+e/v37pwl1AF5eXll+3Y4dO94QvqKjo7ly5QrLli2zt3399decO3eO6OhowAyTn3zyCc2bN8cwDOLj4+2PZs2akZCQwPbt27Ncl4i4PgU7EXFpXbt2Zc2aNXzxxRf06dOHS5cu3bAEybVwdi3gZeT8+fP2c4ODgzN1zc1cu8+vcuXKWX6N9KQ3nFytWjUqVKjA4sWL7W2LFy+mcOHCNG7cGIAzZ85w7tw5PvjgA4oUKZLm0blzZwBOnz7t1FpFxLVoKFZEXFrZsmVp0qQJAI8++ig+Pj7079+f++67j9q1awNQpkwZ8uTJwy+//JLh6yQnJ3PgwIEbrtm9e3e2f4aMeu9SU1Px8fG5oT2jodLo6GhGjhxJfHw8+fPnZ/ny5bRu3Zo8ecy/ym02GwDt2rWjY8eO6b5G1apVs/IRRMRNqMdORNzK66+/Tv78+Rk0aJC9LW/evNx33318++23/P777+let2TJEpKTk3n00UcBCAoKonHjxnz77becOHEiS7WULl0agF9//fWm5xUsWJBz587d0J5RrRmJjo7m6tWrfPLJJ3z11VckJibyzDPP2J8vUqQI+fPnJzU1lSZNmqT7CA0Ndeg9RcS9KNiJiFspUKAAL7zwAqtXr2bnzp329kGDBmEYBp06deLSpUtprjl69CivvfYaERERvPDCC/b2oUOHYhgG7du358KFCze817Zt29JdYuSapk2bkj9/fkaNGsXly5fTPPfPyROlS5fm+++/JyUlxd725ZdfOhwoK1asSJUqVVi8eDGLFy8mIiKCe+65x/68j48PTzzxBJ988km6YfPMmTMOvZ+IuB8NxYqI2+nduzcTJkxg9OjRLFq0CIB77rmHd955h5iYGKpWrWrfeWL//v3MmDEDm83GypUr0yyT0qBBA6ZMmcJLL71EhQoV0uw8sWHDBpYvX86IESMyrCM4OJh3332X5557jjp16tCmTRsKFizIrl27uHjxoj0UPvfccyxdupQHH3yQp59+msOHD/Phhx/ae/wcER0dzZAhQwgICKBLly43LFw8evRo1q9fT7169Xj++eepVKkSZ8+eZfv27axdu5azZ886/J4i4kYMEREXdPToUQMwxo4dm+7znTp1Mnx8fIxDhw6laf/222+NFi1aGIULFzZ8fX2N4sWLG88//7xx7NixDN9r27ZtRps2bYyiRYsavr6+RsGCBY3777/fmDdvnpGamvqftS5fvtxo0KCBERgYaAQHBxt169Y1/ve//6U5Z9y4cUaxYsUMf39/o2HDhsbPP/9sNGrUyGjUqJH9nPXr1xuA8fHHH2f4Xr/99psBGICxefPmdM+Ji4szunfvbkRGRhq+vr5GeHi4cf/99xsffPDBf34WEXFv2lJMRERExEPoHjsRERERD6FgJyIiIuIhFOxEREREPISlwe7bb7+lefPmFC1aFC8vLz777LP/vGbDhg3UrFkTf39/ypQpw9y5c7O9ThERERF3YGmwS0pKolq1akyZMiVT5x89epRHHnmE++67j507d/Lyyy/z3HPPsXr16myuVERERMT1ucysWC8vLz799FNatmyZ4Tn9+vVjxYoVaRbefOaZZzh37hyrVq3KgSpFREREXJdbLVC8detW+56R1zRr1oyXX345w2uSk5NJTk62H9tsNs6ePcttt92W4f6NIiIiItnJMAzOnz9P0aJFb1ho/Fa4VbCLjY0lLCwsTVtYWBiJiYlcunQp3Y2zR40axfDhw3OqRBEREZFMO3HiBLfffrvTXs+tgl1WDBgwgJiYGPtxQkICxYsX58SJEwQHB1tYmYiIiOS0pCQoWtT8+dAhCArKoTe+ehXfSePwHTcaL5uNc6FhlDgdR/78+Z36Nm4V7MLDw4mLi0vTFhcXR3BwcLq9dQD+/v74+/vf0B4cHKxgJyIiksv4+Fz/OTwc8ubNgTc9fBjat4etW83jp5+GMWOgZEmn3xbmVuvY1a9fn3Xr1qVpW7NmDfXr17eoIhEREZGbMAx46ikz1AUHw4IFsGgRFCqULW9nabC7cOECO3fuZOfOnYC5nMnOnTs5fvw4YA6jdujQwX5+t27dOHLkCK+99hr79+9n6tSpLFmyhD59+lhRvoiIiMjNeXnB++9D48bwyy/Qrp3Zlk0sDXY///wzNWrUoEaNGgDExMRQo0YNhgwZAsCpU6fsIQ+gZMmSrFixgjVr1lCtWjXGjRvHzJkzadasmSX1i4iIiNxg1SqYNev6cb16sHYtlCiR7W/tMuvY5ZTExERCQkJISEjQPXYiIiK5TFIS5Mtn/nzhgpPvsbt4Efr1g8mTwd8ftm+HSpXSPTW78ohbTZ4QERERcUnbt5vDrPv2mcddu0LJkjlehltNnhARERFxKampMHo03HmnGeoiIsyh2PfegwxW7MhO6rETERERyQqbDZo1g2srdrRqBR98ALfdZllJCnYiIiLZzDDM26/EeklJTnwxb29ztusPP5g9dJ06ZeuM18xQsBMREclGhgF33QXffWd1JeIUZ8/CX39B2bLmcb9+0LZtjsx4zQzdYyciIpKNLl5UqHNFDRtmYTuxtWuhShV4/HG4fNls8/FxmVAH6rETERHJMXFxObSFlfynoCAHRk0vX4aBA+Hdd83jfPng5EkoVSrb6ssqBTsREZEckjevgp3b2bXLXMbk11/N427d4J13XPaL1FCsiIiIyL/ZbDBuHNSta4a60FD48ktzezAXDXWgYCciIiJyI8Mwg1xKCjz2GOzeDY88YnVV/0lDsSIiIiLXpKaaEyJ8fGDePPj6a+jSxfJlTDJLPXYiIiIi586Zy5b07n29rXhxeO45twl1oGAnIiIiud2GDVC1Knz0EUyfDocPW11RlinYiYiISO6UnAyvvWbuHnHiBJQuDZs2mf91U7rHTkRERHKfPXvModddu8zj554z16nLl8/aum6Rgp2IiHg0q/dpderepOIcycnQtKm5yHDhwjBzJrRoYXVVTqFgJyIiHkv7tEq6/P1h4kSYPdt8hIdbXZHTKNiJiIjHcqV9WrO0N6k4z9Kl5hfw8MPm8ZNPwhNPuNWM18xQsBMRkVzB6n1aHdqbVJwnMRF69TLXpCtc2NxFIizMfM4DvxAFOxERyRW0T2sutHkztG8Px46Btze88AIULGh1VdlKwU5EREQ8S0oKDBsGY8aYe76WLAkLFpjj4R5OwU5EREQ8R1IS3HMPbN9uHnfqZE6UCA62tKycogWKRURExHPkzQs1akChQvDxxzBnTq4JdaBgJyIiIu4uNtZ8XDNhAvzyiznzNZdRsBMRERH39dlnUKUKdOxo3k8H5u4RxYpZWpZVFOxERETE/Vy4YG4D9vjjEB8Pp0/D2bNWV2U5TZ4QEfFQVm+l5Qq0nZeH2rrVXMbk8GFzLbpXX4U33jB3lMjlFOxERDyQttISj3TlCowYYT5sNiheHObPh0aNrK7MZWgoVkTEA7nSVlquQNt5eYgrV2DRIjPUtW0Lu3Yp1P2LeuxERDyc1VtpuQJt5+XGDMN8eHubX+SHH8KhQ9C6tdWVuSQFOxERD6ettMRtnT5tTpC4916IiTHb6tQxH5IuDcWKiIiI6/nyS3MZky++MLcHO3fO6orcgoKdiIiIuI6kJHjxRWje3Oyxq1wZNm+GAgWsrswtKNiJiIiIa/jpJ6hZE6ZNM49jYsy2qlWtrcuN6B47ERERsV58vHkv3cWL5q4R8+bB/fdbXZXbUbATERER6xUuDEOGwPbt8P77UKiQ1RW5JQU7ERERyXmGAXPnQvXqUKOG2fbaa+Z/tTZNlukeOxEREclZ8fHw5JPw7LPmQsOXLpntXl4KdbdIPXYi4lG0P6pJe6SKy1q9Gjp1gthY8PWFDh3Az8/qqjyGgp2IeAztjyriwi5dgn79YNIk87hiRXMXiZo1ra3LwyjYiYjH0P6oN9IeqeISYmOhcWPYt8887tkTxoyBwEBr6/JACnYi4pG0P6pJe6SKSwgNhYgI+Ptvc8JEs2ZWV+SxFOxExCNpf1QRi/3+u7mESd684O1tDrv6+pptkm00K1ZEREScxzBgwQJzt4i+fa+3R0Qo1OUABTsRERFxjrNn4ZlnzJmuiYnwyy9w+bLVVeUqCnYiIiJy69atM3vpliyBPHlgxAjYuBECAqyuLFfRPXYiIiKSdZcvw8CB8O675nG5cub9dHXqWFtXLqUeOxEREcm6v/+G+fPNn7t1M/d6VaizjHrsRERExDGGcX0dnYgIcwkTgEcftawkManHTkRERDLvxAlo0gQ+++x626OPKtS5CPXYiQjgGXusan9UkWy2aBG8+CKcOweHD8Mjj5hr04nLULATEe2xKiI3d+4c9OgBCxeax3XrXl9wWFyKhmJFxOP2WNX+qCJOtGGDuYzJwoXg4wNDh8LmzVC2rNWVSTrUYyciaXjCHqvaH1XESfbvh8aNzW790qXNHSXq17e6KrkJBTsRSUN7rIqIXYUK8NxzZrB7913Il8/qiuQ/KNiJiIiIyWaDqVPh8cehWDGz7f33zSFYcQu6x05ERETg5El48EHo2RM6dTJDHijUuRkFOxERkdxu6VKoUgXWrDH3dm3ZUjequikNxYqIiORWiYnQqxfMm2ce16xpzn6tUMHauiTLFOxERERyowMHzKHXY8fA2xv69zeXMvHzs7oyuQUKdiIiIrlRZKQ57BoVZS5jctddVlckTqBgJ+IE7r4dl7biEskljhyBEiXMCRFBQbB8OYSFQXCw1ZWJkyjYidwibcclIi7PMGDaNHjlFRg+HF591WzX7hEeR7NiRW6RJ23Hpa24RDxQbCw8+ii89BJcugQbN5pBTzySeuxEnMjdt+PSVlwiHubzz82dI+Ljwd8fxowx16nTH3SPpWAn4kTajktEXMKFC9CnD8ycaR5XqwYffgiVK1tbl2Q7y4dip0yZQlRUFAEBAdSrV48ff/zxpudPmDCB8uXLExgYSGRkJH369OHy5cs5VK2IiIgbOHIE5s83e+ZefRV++EGhLpewtMdu8eLFxMTEMG3aNOrVq8eECRNo1qwZBw4cIDQ09IbzP/roI/r378/s2bNp0KABBw8epFOnTnh5eTF+/HgLPoGIiIiLMIzrQ6xVq8KUKVCmDNx7r6VlSc6ytMdu/PjxPP/883Tu3JlKlSoxbdo0goKCmD17drrnf/fddzRs2JA2bdoQFRVF06ZNad269X/28omIiHi0336De+6Bbduutz33nEJdLmRZsEtJSWHbtm00adLkejHe3jRp0oStW7eme02DBg3Ytm2bPcgdOXKElStX8vDDD2f4PsnJySQmJqZ5iIiIeATDgBkzoHp12LwZevTQjNdczrKh2Pj4eFJTUwkLC0vTHhYWxv79+9O9pk2bNsTHx3PXXXdhGAZXr16lW7duDBw4MMP3GTVqFMOHD3dq7SIiIpY7fRqef95cZBjgvvvMPV814zVXs3zyhCM2bNjAW2+9xdSpU9m+fTvLli1jxYoVvPnmmxleM2DAABISEuyPEydO5GDFIiIi2WDFCqhSxQx1fn7wzjuwdq25TZjkapb12BUuXBgfHx/i4uLStMfFxREeHp7uNYMHD6Z9+/Y899xzAFSpUoWkpCS6du3K66+/jrf3jTnV398ff39/538AERERK3zzjbngMJgzXRcuNCdLiGBhj52fnx+1atVi3bp19jabzca6deuoX79+utdcvHjxhvDm4+MDgKF7CiSLDMPcK/VWHiIiOebee6FpU3Odup9+UqiTNCxd7iQmJoaOHTtSu3Zt6taty4QJE0hKSqJz584AdOjQgWLFijFq1CgAmjdvzvjx46lRowb16tXj0KFDDB48mObNm9sDnogjtM+riLi8q1fh/fehc2fIlw+8vc2h2DzaY0BuZOnviujoaM6cOcOQIUOIjY2levXqrFq1yj6h4vjx42l66AYNGoSXlxeDBg3izz//pEiRIjRv3pyRI0da9RHEzTlzn1ftsyoiTnfkCLRvb/5F9euvMH262a5QJxnwMnLZGGZiYiIhISEkJCQQHBxsdTlisaQk8x/AcOv7vGqfVRFxGsMwZ7j27GluDxYcDJMnmyFPPEJ25RFFfpH/p31eRcQl/PUXdO0Ky5aZx3ffbW4PFhVlaVniHtxquRMRERGP9uOP5jImy5aBry+MGgXr1yvUSaapx05ERMRVFC8OV65AhQrmMiY1a1pdkbgZBTsREREr/f47lChh/hweDl9/DeXLazaWZImGYkVERKyQmgpjxkDZsvDJJ9fba9RQqJMsU7ATERHJaceOmXu79u9vDr1+9ZXVFYmHULATERHJKYYBH34I1arBpk3mekuzZ8OMGVZXJh5C99iJiIjkhL//hhdfhMWLzeP69WHBAihd2tq6xKMo2IlbMwxz94is0j6vIpJjvv/eDHU+PjB0KAwYoB0kxOn0O0rclvZ5FRG38tBDMGIEPPAA1K1rdTXioXSPnbgt7fMqIi5t925o1AhOnLje9vrrCnWSrdRjJx5B+7yKiMuw2WDCBHOoNSUFXnkFliyxuirJJRTsxCNon1cRcQknTkCnTvDNN+bxo4/CpEmWliS5i4ZiRUREnGHxYqha1Qx1QUEwfTosXw5hYVZXJrmIeuxERERu1YIF0KGD+XPduuZxuXLW1iS5knrsREREbtWTT0KVKjBkCGzerFAnllGPnYiIiKNSUmDWLOja1VyXLjAQfv4Z/PysrkxyOQU7ERERR+zdC23bws6dkJgI/fqZ7Qp14gI0FCsiIpIZNps5w7VWLTPU3XYblC9vdVUiaajHTkRE5L+cPAnPPgurV5vHDz4Is2dDRIS1dYn8i3rsREREbmbNGnMZk9WrISAApkyBlSsV6sQlqcdORETkZsLD4fx5qFkTPvwQKla0uiKRDCnYiYiI/NupU9d75KpUgXXrzPXpNEFCXJyGYkVERK65cgUGDYKSJeGnn66333WXQp24BQU7ERERgAMHoEEDGDkSkpPN7cBE3IyGYkVEJHczDJg2DV55BS5dgoIF4YMPzN0kRNyMgp2IiOResbHQpYs5yxXggQdgzhwoVszaukSySEOxIiKSe332mRnq/P1hwgRYtUqhTtyaeuxERCT3euEF2L8fnnsOKle2uhqRW6YeOxERyT1++MHcNeL8efPYy8vsqVOoEw+hYCciIp7v6lUYNgwaNjR3kHjjDasrEskWGooVERHP9ttv0L692VsH0KYNvP66tTWJZBP12ImIiGcyDJg5E2rUMENdSAh89BEsXAgFClhdnUi2UI+diIh4pjFjYMAA8+d774V586B4cUtLEslu6rETERHP1Lkz3H47jB1r7vWqUCe5gHrsRETEM1y8CEuXQocO5nFYGBw8CIGB1tYlkoMU7ERExP39/DO0a2fu9xoYCE89ZbYr1Ekuo6FYERFxX6mpMHIk1K9vhrqiRaFQIaurErGMeuxERMQ9HT1qLmOyZYt5/NRTMG2agp3kauqxExER97N4MVStaoa6/Plh/nyzTaFOcjn12ImIiPsJDoYLF+Cuu2DBAoiKsroiEZegYCciIu7hzBkoUsT8+aGHzK3B7r8ffHysrUvEhSjYiaUMw1yhICuSkpxbi4i4qEuXoH9/c7h1167r69E1bWptXSIuSMFOLGMY5ijKd99ZXYmIuKydO6FtW9i71zz+4gvo3t3SkkRcmSZPiGUuXnROqGvYEIKCbv11RMSFpKbC229D3bpmqAsPh5UrFepE/oN67MQlxMVB3rxZuzYoCLy8nFuPiFjo99+hY0fYuNE8btkSZsyAwoUtLUvEHSjYiUvImzfrwU5EPMz775uhLl8+mDjR3PNV/3oTyZRbCnaXL18mICDAWbWIiIjAsGFmN/6gQVC6tNXViLgVh++xs9lsvPnmmxQrVox8+fJx5MgRAAYPHsysWbOcXqCIiHi4b76BZ54x76sDCAiAOXMU6kSywOFgN2LECObOncvbb7+Nn5+fvb1y5crMnDnTqcWJiIgHu3wZXnnFXItu8WKYOtXqikTcnsPBbv78+XzwwQe0bdsWn38sClmtWjX279/v1OJERMRD7d5tzngdP948fuEFePZZa2sS8QAOB7s///yTMmXK3NBus9m4cuWKU4oSEREPZbOZYa52bTPcFSkCy5fDtGmaQSXiBA4Hu0qVKrFp06Yb2pcuXUqNGjWcUpSIiHio3r3N4deUFHj0UTPcNW9udVUiHsPhWbFDhgyhY8eO/Pnnn9hsNpYtW8aBAweYP38+X375ZXbUKCIinqJbN/joIxg1Cp5/XsuYiDiZwz12LVq04IsvvmDt2rXkzZuXIUOGsG/fPr744gseeOCB7KhRRETcVUICfPbZ9eM77jAXIO7aVaFOJBtkaR27u+++mzVr1ji7FhER8STffgvt28Off8KWLVCvntmeL5+1dYl4MId77EqVKsVff/11Q/u5c+coVaqUU4oSERE3lpIC/fvDvffC8eNQooR650RyiMM9dseOHSP12iKS/5CcnMyff/7plKJERMRN7d0LbdvCzp3m8bPPwoQJkD+/lVWJ5BqZDnbLly+3/7x69WpCQkLsx6mpqaxbt46oqCinFiciIm5k+nR4+WVz4eHbboMZM+Dxx62uSiRXyXSwa9myJQBeXl507NgxzXO+vr5ERUUxbtw4pxYnIiJuJDXVDHXNmplbgkVEWF2RSK6T6WBns9kAKFmyJD/99BOFCxfOtqJERMRN/P03FCxo/vzii1C0KLRooXvqRCzi8OSJo0ePKtSJiOR2iYnQuTPUrGn+DGaYa9lSoU7EQlla7iQpKYmNGzdy/PhxUlJS0jzXq1cvpxQmIiIuassWcxmTo0fNELdmDTzxhNVViQhZCHY7duzg4Ycf5uLFiyQlJVGoUCHi4+MJCgoiNDRUwU5ExFNduQLDh5u7Rths5jImCxbA3XdbXZmI/D+Hh2L79OlD8+bN+fvvvwkMDOT777/n999/p1atWrzzzjvZUaOIiFjtwAFo0ABGjjRDXYcOsGuXQp2Ii3E42O3cuZNXXnkFb29vfHx8SE5OJjIykrfffpuBAwdmR40iImK1IUPg55/NiRKLF8O8efCPZa9ExDU4HOx8fX3x9jYvCw0N5fjx4wCEhIRw4sQJhwuYMmUKUVFRBAQEUK9ePX788cebnn/u3Dm6d+9OREQE/v7+lCtXjpUrVzr8viIi4oBJkyA6Gn75BZ5+2upqRCQDDt9jV6NGDX766SfKli1Lo0aNGDJkCPHx8SxYsIDKlSs79FqLFy8mJiaGadOmUa9ePSZMmECzZs04cOAAoaGhN5yfkpLCAw88QGhoKEuXLqVYsWL8/vvvFChQwNGPISIiN7N8OaxbBxMnmsehobBokbU1ich/8jIMw3Dkgp9//pnz589z3333cfr0aTp06MB3331H2bJlmTVrFtWrV8/0a9WrV486deowefJkwFwrLzIykp49e9K/f/8bzp82bRpjx45l//79+Pr6OlK2XWJiIiEhISQkJBAcHJyl1xDnSEq6vhf4hQuQN6+19YgI5h/GmBhz1wgwA17z5tbWJOKBsiuPOBzsnCUlJYWgoCCWLl1q39UCoGPHjpw7d47PP//8hmsefvhhChUqRFBQEJ9//jlFihShTZs29OvXDx8fn3TfJzk5meTkZPtxYmIikZGRCnYuQMFOxMX88AO0aweHDpnLmLzyCowYAf7+Vlcm4nGyK9g5fI9dRrZv386jjz6a6fPj4+NJTU0lLCwsTXtYWBixsbHpXnPkyBGWLl1KamoqK1euZPDgwYwbN44RI0Zk+D6jRo0iJCTE/oiMjMx0jSIiucLVq/DGG9CwoRnqIiPNYdixYxXqRNyMQ8Fu9erV9O3bl4EDB3LkyBEA9u/fT8uWLalTp45927HsYrPZCA0N5YMPPqBWrVpER0fz+uuvM23atAyvGTBgAAkJCfZHViZ4iIh4tOhoGDrU3Ou1dWtzgsR991ldlYhkQaYnT8yaNYvnn3+eQoUK8ffffzNz5kzGjx9Pz549iY6O5tdff6VixYqZfuPChQvj4+NDXFxcmva4uDjCw8PTvSYiIgJfX980w64VK1YkNjaWlJQU/Pz8brjG398ff/2LU0QkY127wjffwJQp0KaN1dWIyC3IdI/dxIkTGTNmDPHx8SxZsoT4+HimTp3K7t27mTZtmkOhDsDPz49atWqxbt06e5vNZmPdunXUr18/3WsaNmzIoUOH0vQMHjx4kIiIiHRDnYiIpOPMGVi//vpxs2Zw7JhCnYgHyHSwO3z4ME899RQArVq1Ik+ePIwdO5bbb789y28eExPDjBkzmDdvHvv27ePFF18kKSmJzp07A9ChQwcGDBhgP//FF1/k7Nmz9O7dm4MHD7JixQreeustunfvnuUaRERylZUroUoVaNnSDHPXaLFhEY+Q6aHYS5cuERQUBICXlxf+/v5ERETc0ptHR0dz5swZhgwZQmxsLNWrV2fVqlX2CRXHjx+3L4YMEBkZyerVq+nTpw9Vq1alWLFi9O7dm379+t1SHSIiHu/iRXj1VZg61TyuVMlsExGPkunlTry9vRkxYgT5/n99in79+vHqq69SuHDhNOf16tXL+VU6kdaxcx1a7kQkh2zbBm3bmvu9AvTuDaNGQWCgtXWJ5GKWr2MXFRWFl5fXzV/My8s+W9ZVKdi5DgU7kRwwejQMHmwuaVK0KMydCw88YHVVIrleduWRTA/FHvvnvRgiIuIezpwxQ92TT8L06VCokNUViUg2cnivWBERcWGGYXaB589vHo8cCQ0aQKtW5m4SIuLRnLbzhIiIWOyvv+Cpp+DBB81eOoCAAHjiCYU6kVxCwU5ExBN8/bW5jMknn8CPP5r7vopIrqNgJyLizi5dMme5NmsGp05BhQrw/ffmvq8ikuvoHjsREXe1Ywe0awd795rH3bvD22/D/685KiK5T5Z67A4fPsygQYNo3bo1p0+fBuCrr75iz549Ti1OREQyYBjw4otmqAsLgxUrYPJkhTqRXM7hYLdx40aqVKnCDz/8wLJly7hw4QIAu3btYujQoU4vUERE0uHlBXPmQHQ07N4NDz9sdUUi4gIcDnb9+/dnxIgRrFmzBj8/P3t748aN+f77751anIiI/MNHH5lDrddUrAiLFkGRItbVJCIuxeF77Hbv3s1HH310Q3toaCjx8fFOKUpERP7h77/hpZfMEOftDU2aQM2aVlclIi7I4R67AgUKcOrUqRvad+zYQbFixZxSlIiI/L9vvoGqVc1Q5+MDw4aZxyIi6XA42D3zzDP069eP2NhYvLy8sNlsbNmyhb59+9KhQ4fsqFFEJPdJToa+feH+++GPP6BMGdiyxdz3NY8WNBCR9Dkc7N566y0qVKhAZGQkFy5coFKlStxzzz00aNCAQYMGZUeNIiK5i80G990H48aZx127mkub1KtnbV0i4vIc/mefn58fM2bMYPDgwfz6669cuHCBGjVqULZs2eyoT0Qk9/H2hg4d4NAhmDkTHnvM6opExE14GYZhOHLB5s2bueuuu7KrnmyXmJhISEgICQkJBAcHW11OrpaUBPnymT9fuAB581pbj4il/vgDTp++PinCMODsWbjtNmvrEpFskV15xOGh2MaNG1OyZEkGDhzI3murnYuISNYtWWLu89qqFSQkmG1eXgp1IuIwh4PdyZMneeWVV9i4cSOVK1emevXqjB07lj/++CM76hMR8VwJCeaQa3Q0nDtnrkd3LdiJiGSBw8GucOHC9OjRgy1btnD48GGeeuop5s2bR1RUFI0bN86OGkVEPM+mTVCtGixYYN5TN3gwfPcdFC9udWUi4sZuac58yZIl6d+/P9WqVWPw4MFs3LjRWXWJiHim1FQYNAjGjDHvoytVygx3DRpYXZmIeACHe+yu2bJlCy+99BIRERG0adOGypUrs2LFCmfWJiLieby9Yf9+M9Q9+yzs3KlQJyJO43CP3YABA1i0aBEnT57kgQceYOLEibRo0YKgoKDsqE9ExP0ZBly+DIGB5qSIGTOgUydo0cLqykTEwzgc7L799lteffVVnn76aQoXLpwdNYmIeI5Tp6BzZyhUCK7ts124sEKdiGQLh4Pdli1bsqMOERHPs2yZuWvEX39BQAD89htoMXcRyUaZCnbLly/noYcewtfXl+XLl9/03Me0QrqI5Hbnz0Pv3jBnjnlcvTosXKhQJyLZLlM7T3h7exMbG0toaCje3hnPt/Dy8iI1NdWpBTqbdp5wHdp5QjzSd99B+/Zw5Ih5P12/fjB8OPj5WV2ZiLiQ7Mojmeqxs9ls6f4sIiL/kJICrVvD8eNQogTMnw/33GN1VSKSizi83Mn8+fNJTk6+oT0lJYX58+c7pSgREbfk5wezZpk9drt2KdSJSI7L1FDsP/n4+HDq1ClCQ0PTtP/111+EhoZqKFYyTUOx4vYMA6ZPh/z5oW1bq6sRETdi6VDsPxmGgZeX1w3tf/zxByEhIU4pSkTE5cXFQZcusGKF+S+URo3g9tutrkpEcrlMB7saNWrg5eWFl5cX999/P3nyXL80NTWVo0eP8uCDD2ZLkSIiLmX5cnjuOThzBvz94c03oWhRq6sSEcl8sGvZsiUAO3fupFmzZuS7NoYG+Pn5ERUVxRNPPOH0AkVEXMaFCxATY+4cAVClirmMSZUq1tYlIvL/Mh3shg4dCkBUVBTR0dEEBARkW1EiIi7n0iWoVQsOHjSXMXnlFRgxwuyxExFxEQ7Piu3YsaNCnYjkPoGB0LKleR/d2rUwdqxCnYi4nEzNii1UqBAHDx6kcOHCFCxYMN3JE9ecPXvWqQU6m2bFug7NihWXd/iw2TtXqpR5nJwMFy9CwYLW1iUibs/SWbHvvvsu+fPnt/98s2AnuYdhmP+Py6qkJOfVIuJUhgGzZ5vbglWuDJs3Q548Zg+deulExIVlKth17NjR/nOnTp2yqxZxI4YBd91l7p4k4lHOnIGuXeGzz8zjgABISIDbbrO0LBGRzHD4Hrvt27eze/du+/Hnn39Oy5YtGThwICkpKU4tTlzXxYvOC3UNG0JQkHNeS+SWfPWVOcP1s8/A1xfefhvWrVOoExG34XCwe+GFFzh48CAAR44cITo6mqCgID7++GNee+01pxcori8uzrxHLquPTZvM25hELHPpEnTvDg8/bP6GrlQJfvwRXn0VfHysrk5EJNMc3nni4MGDVK9eHYCPP/6YRo0a8dFHH7FlyxaeeeYZJkyY4OQSxdXlzauJD+LmfHzghx/Mn3v3hlGjzFmwIiJuJktbitlsNgDWrl3Lo48+CkBkZCTx8fHOrU5EJLukpoLNZg65+vnBhx/C8ePQtKnVlYmIZJnDQ7G1a9dmxIgRLFiwgI0bN/LII48AcPToUcLCwpxeoIiI0x09au7tOnz49bYKFRTqRMTtORzsJkyYwPbt2+nRowevv/46ZcqUAWDp0qU0aNDA6QWKiDiNYcC8eVCtGmzZAlOmwN9/W12ViIjTZGqB4sy4fPkyPj4++Pr6OuPlso0WKHYOLS4sbuevv6BbN1i61Dxu2BAWLICSJa2tS0RyJUsXKE7Ptm3b2LdvHwCVKlWiZs2aTitKRMSp1qyBTp3g5ElzoeHhw6FfP814FRGP43CwO336NNHR0WzcuJECBQoAcO7cOe677z4WLVpEkSJFnF2jiEjWnT0LrVqZXcvly8PChVCrltVViYhkC4fvsevZsycXLlxgz549nD17lrNnz/Lrr7+SmJhIr169sqNGEZGsK1QIxo+Hl16C7dsV6kTEozl8j11ISAhr166lTp06adp//PFHmjZtyrlz55xZn9PpHrvrbmWv16QkuDYJWvfYiUtJTTWDXN265sxXEREX5DL32NlstnQnSPj6+trXtxPXp71exSMdPw4dOsDGjVC8OPz6K+TPb3VVIiI5xuGh2MaNG9O7d29Onjxpb/vzzz/p06cP999/v1OLk+zjrL1etc+ruIyPPoKqVc1QlzcvDB58feq2iEgu4XCP3eTJk3nssceIiooiMjISgBMnTlC5cmU+/PBDpxco2S8uLutDqUFB2udVLPb33+Y+r//7n3l8553mMib/v8amiEhu4nCwi4yMZPv27axbt86+3EnFihVp0qSJ04uTnKG9XsVtxcaa99KdOGEuXTJkCAwcaC5pIiKSCzn0t9/ixYtZvnw5KSkp3H///fTs2TO76hIR+W9hYWaw8/c393qtV8/qikRELJXpYPf+++/TvXt3ypYtS2BgIMuWLePw4cOMHTs2O+sTEUnr11+haFFzGRMvL5gxA3x9dT+diAgOTJ6YPHkyQ4cO5cCBA+zcuZN58+YxderU7KxNROQ6mw3efRdq1za3Bru2UlPBggp1IiL/L9PB7siRI3Ts2NF+3KZNG65evcqpU6eypTAREbs//oCmTSEmBpKTzWndly9bXZWIiMvJdLBLTk4m7z/usPf29sbPz49Lly5lS2EiIgAsWQJVqsC6dRAYCO+/D198Yf4sIiJpODR5YvDgwQT9Y9GylJQURo4cSUhIiL1t/PjxzqtORHKvxETo0cNcugTMIdgPPzT3exURkXRlOtjdc889HDhwIE1bgwYNOHLkiP3YSwuaiYizpKbC+vXg7W0uYTJkiDlJQkREMpTpYLdhw4ZsLEMcdSv7vIK516uIy7lyxVyDzsvLnBTx0UdmsGvY0OrKRETcglbxdEPa51U80r590LatOfz67LNm2913W1uTiIibcXivWLGes/Z5Be31Ki7AMGDyZKhZE3bsgDffhJQUq6sSEXFL6rFzc7eyzytor1ex2KlTZu/cqlXmcbNmMGcO+PlZW5eIiJtSsHNz2udV3NayZdC1K/z1FwQEwNix0L27/qUhInILFOxEJOcdPAhPPmkOw1avDgsXQqVKVlclIuL2snSP3aZNm2jXrh3169fnzz//BGDBggVs3rw5S0VMmTKFqKgoAgICqFevHj/++GOmrlu0aBFeXl60bNkyS+8rIhYpVw4GDIB+/eCHHxTqREScxOFg98knn9CsWTMCAwPZsWMHycnJACQkJPDWW285XMDixYuJiYlh6NChbN++nWrVqtGsWTNOnz590+uOHTtG3759uVuz5kRc35UrMGyY2VN3zYgRMHq07qcTEXEih4PdiBEjmDZtGjNmzMD3H4uFNmzYkO3btztcwPjx43n++efp3LkzlSpVYtq0aQQFBTF79uwMr0lNTaVt27YMHz6cUqVKOfyeIpKDDh40p18PHw7t2pkLD4PupRMRyQYOB7sDBw5wzz333NAeEhLCuXPnHHqtlJQUtm3bRpMmTa4X5O1NkyZN2Lp1a4bXvfHGG4SGhtKlSxeH3k9EcpBhwPTpUKMG/PQTFCgAr7wCPj5WVyYi4rEcnjwRHh7OoUOHiIqKStO+efNmh3vP4uPjSU1NJSwsLE17WFgY+/fvT/eazZs3M2vWLHbu3Jmp90hOTrYPFwMkJiY6VKOIZEFcHDz3HHz5pXl8//0wdy7cfrulZYmIeDqHe+yef/55evfuzQ8//ICXlxcnT55k4cKF9O3blxdffDE7arQ7f/487du3Z8aMGRQuXDhT14waNYqQkBD7IzIyMltrFMn19u2DKlXMUOfnB+PHw9dfK9SJiOQAh3vs+vfvj81m4/777+fixYvcc889+Pv707dvX3r27OnQaxUuXBgfHx/i4uLStMfFxREeHn7D+YcPH+bYsWM0b97c3maz2cwPkicPBw4coHTp0mmuGTBgADExMfbjxMREhTuR7FSmDERFQXi4uYxJlSpWVyQikmt4GYZhZOXClJQUDh06xIULF6hUqRL58uXLUgH16tWjbt26TJo0CTCDWvHixenRowf9+/dPc+7ly5c5dOhQmrZBgwZx/vx5Jk6cSLly5fD7jxl2iYmJhISEkJCQQHBwcJZqtlpSElz75b5wQQsUiwvYsQPuuOP6DNeTJ6FQIXPhYRERuUF25ZEsL1Ds5+dHJSesPRUTE0PHjh2pXbs2devWZcKECSQlJdG5c2cAOnToQLFixRg1ahQBAQFUrlw5zfUFChQAuKFdRHLA1avw1lvwxhvw6qswapTZXrSotXWJiORSDge7++67D6+bLFPwzTffOPR60dHRnDlzhiFDhhAbG0v16tVZtWqVfULF8ePH8fbO0jrKIpKdDh82ly/5/nvz+PhxsNlAf15FRCzj8FBsnz590hxfuXKFnTt38uuvv9KxY0cmTpzo1AKdTUOxIrfIMGD2bOjd2/zNGBwMU6dCmzZam05EJJNcZij23XffTbd92LBhXLhw4ZYLEhEXFh8Pzz8Pn31mHjdqBPPmQYkSlpYlIiImp42ZtGvX7qa7RYiIB0hIgDVrwNcXxoyBdesU6kREXEiWJ0/829atWwnQDDgRz5Oaen23iNKlYcECKFkSqle3tCwREbmRw8GuVatWaY4Nw+DUqVP8/PPPDB482GmFiYgL2L4d2reHSZOgcWOz7fHHra1JREQy5HCwCwkJSXPs7e1N+fLleeONN2jatKnTChMRC6Wmwttvw5Ah5pImAwaYs181OUJExKU5FOxSU1Pp3LkzVapUoWDBgtlVk4hY6dgxs5du82bzuFUr+OADhToRETfgULDz8fGhadOm7Nu3L1cHO8OAixete/+kJOveWzyYYZj3z/XoAefPm2vqTJoEHTsq1ImIuAmHh2IrV67MkSNHKFmyZHbU4/IMA+66C777zupKRJxs40YzxAE0bAjz50OpUtbWJCIiDnF4uZMRI0bQt29fvvzyS06dOkViYmKah6e7eNF1Ql3DhhAUZHUV4jEaNYK2bWHkSDPkKdSJiLidTO888cYbb/DKK6+QP3/+6xf/Y3jGMAy8vLxITU11fpVOdKsrPf9z14e4OGt3fQgK0giZ3ILLl80Q9/LLcNttZpth6DeViEgOyK6dJzId7Hx8fDh16hT79u276XmNGjVySmHZxZnBTtt5idvatcvsnduzB554ApYutboiEZFcxfItxa7lP1cPbiJyEzYbjB8Pr78OKSkQFgbPPmt1VSIi4iQOTZ7w0hCNiPs6ftycHLFhg3ncogXMmAFFilhaloiIOI9Dwa5cuXL/Ge7Onj17SwWJSDbYsgUeecTc6zVvXpg40eyp0z/WREQ8ikPBbvjw4TfsPCEibuCOOyA4GCpUgA8/hDJlrK5IRESygUPB7plnniE0NDS7ahERZ9q1C6pWNXvlChSA9euhRAnI4/DylSIi4iYyvY6d7q8TcRPJyfDqq1CjBsyadb29dGmFOhERD+fwrFgRcWG//mouY/LLL+bxnj3W1iMiIjkq08HOZrNlZx0icitsNnjvPejf3+yxK1zY7K177DGrKxMRkRykcRkRd/fnn9CpE6xdax4//LAZ6sLDLS1LRERynsN7xYqIizl2DL75BgID4f334csvFepERHIp9diJuCObDbz//99lDRuaga5RIyhf3tq6RETEUuqxE3E3mzZB5cqwf//1tq5dFepERETBTsRtpKTAgAFmz9y+feZ+ryIiIv+goVgRd7Bvn7mMyY4d5nHnzjBhgqUliYiI61GPnYgrMwyYMgVq1jRDXaFC8MknMHu2uUWYiIjIP6jHTsSVLVgAPXqYPzdrZga6okWtrUlERFyWeuxEXFnr1nDvvTBpEnz1lUKdiIjclHrsRFzJ+fMwfry5g4S/P/j6mmvUaa9mERHJBAU7EVexdSu0awdHjsDFizBmjNmuUCciIpmkoVgRq125AkOGwF13maGueHFzWzAREREHqcdOxEoHD5q9dD/9ZB63aweTJ0NIiLV1iYiIW1KwE7HK8uXm5IiLF6FAAZg2DaKjra5KRETcmIKdiFWqVAEfH2jcGObNg9tvt7oiERFxcwp2Ijlp3z6oWNH8uWRJc8JExYrgrdtdRUTk1un/JiI5ISkJunWDO+6AtWuvt99xh0KdiIg4jf6PIpLdfvoJatSA6dPNLcKuTZQQERFxMgU7kexy9Sq8+SbUrw+//QbFisG6dTBggNWViYiIh9I9diLZ4fBhaN/evIcOzNmu778PBQtaW5eIiHg0BTuR7PDDD2aoCw6GqVOhTRvtICEiItlOwU7EWQzjenhr0wZ+/938b4kS1tYlIiK5hu6xE3GGVaugdm2Ij7/eNmCAQp2IiOQoBTuRW3HxIvTsCQ89BNu3w8iRVlckIiK5mIZiRbJq+3Zo2xb27zePe/WCt96ytiYREcnV1GMn4qjUVBg1CurVM0NdRASsXg0TJ0JgoNXViYhILqZgJ+KoMWNg4EBznbpWrWD3bmja1OqqREREFOxEHNa9O1SpAnPmwNKlcNttVlckIiICKNiJ/LezZ2HsWHM5E4CQENixAzp10tp0IiLiUjR5QuRm1qwxA9zJk+Ziwy+8YLb7+FhaloiISHrUYyeSnsuXoU8f8965kyehXDmoVcvqqkRERG5KPXYi/7Zrl7mMyZ495vGLL5pDsXnzWluXiIjIf1CwE/mnOXOgWzdISYHQUJg9Gx55xOqqREREMkVDsSL/VKGCuYzJY4+Zy5go1ImIiBtRj53IoUNQpoz5c/368OOPULOmZryKiIjbUY+d5F7nzpn30lWpAnv3Xm+vVUuhTkRE3JKCneROGzZA1arw0Udw5Qp8953VFYmIiNwyBTvJXZKT4bXXoHFjOHECSpeGzZvhueesrkxEROSW6R47yT1+/RXatTOXMwEzzL37LuTLZ21dIiIiTqJgJ7nHZ5+Zoa5wYZg5E1q0sLoiERERp1KwE89mGNcnQvTvDxcuwMsvQ3i4pWWJiIhkB91jJ55r6VLzXrrLl83jPHlg9GiFOhER8VgKduJ5EhOhUyd46ilz9uvUqVZXJCIikiM0FCueZfNmaN8ejh0Db28YMAB69LC6KhERkRyhYCeeISUFhg83h1ptNihZEhYsgIYNra5MREQkxyjYiWd4+WV4/33z506dYOJECA62siIREZEcp3vsxDO89prZS7d0KcyZo1AnIiK5kksEuylTphAVFUVAQAD16tXjxx9/zPDcGTNmcPfdd1OwYEEKFixIkyZNbnq+eKjYWHMtumuiouDgQXjiCctKEhERsZrlwW7x4sXExMQwdOhQtm/fTrVq1WjWrBmnT59O9/wNGzbQunVr1q9fz9atW4mMjKRp06b8+eefOVy5WObTT6FyZXj+efj66+vteXRngYiI5G5ehmEYVhZQr1496tSpw+TJkwGw2WxERkbSs2dP+vfv/5/Xp6amUrBgQSZPnkyHDh3+8/zExERCQkJISEggOAvDdUlJ13egunAB8uZ1+CUkq64tLjxrlnlcvTosXAiVKllZlYiIiMNuNY9kxNIeu5SUFLZt20aTJk3sbd7e3jRp0oStW7dm6jUuXrzIlStXKFSoUHaVKa5g61YzyM2aZe4k0a8f/PCDQp2IiMg/WDp2FR8fT2pqKmFhYWnaw8LC2L9/f6Zeo1+/fhQtWjRNOPyn5ORkkpOT7ceJiYlZL1isMXasuR2YzQbFi8P8+dCokdVViYiIuBzL77G7FaNHj2bRokV8+umnBAQEpHvOqFGjCAkJsT8iIyNzuEq5ZZGRZqhr1w5++UWhTkREJAOWBrvChQvj4+NDXFxcmva4uDjC/2M/z3feeYfRo0fz9ddfU7Vq1QzPGzBgAAkJCfbHiRMnnFK7ZCPDgOPHrx8/8wxs2WIuOBwSYl1dIiIiLs7SYOfn50etWrVYt26dvc1ms7Fu3Trq16+f4XVvv/02b775JqtWraJ27do3fQ9/f3+Cg4PTPMSFnT4NLVpAnTrmz9c0aGBdTSIiIm7C8qHYmJgYZsyYwbx589i3bx8vvvgiSUlJdO7cGYAOHTowYMAA+/ljxoxh8ODBzJ49m6ioKGJjY4mNjeXChQtWfQRxli+/hCpV4Isv4Nw5c8KEiIiIZJrlC39FR0dz5swZhgwZQmxsLNWrV2fVqlX2CRXHjx/H2/t6/nz//fdJSUnhySefTPM6Q4cOZdiwYTlZujhLUhK88gpMn24eV65sLmNykyF2ERERuZHl69jlNK1j52J++gnatoXffjOPY2Jg5EjIYDKMiIiIJ8iudews77GTXG7aNDPUFSsG8+bB/fdbXZGIiIjbUrATa737rtntOWwYaJFpERGRW2L55AnJRQwDZs+G6GjzZ4DgYHjvPYU6ERERJ1Cwk5wRHw9PPAFdusCSJbB0qdUViYiIeBwFO8l+q1aZy5h8+in4+sLo0dCqldVViYiIeBzdYyfZ59IleO01mDzZPK5Y0VzGpEYNa+sSERHxUAp2kn2io83FhgF69oQxYyAw0NqaREREPJiGYiX7DBwIkZHmUOx77ynUiYiIZDP12InzHDsG27aZkyQA7rwTDh0CPz9LyxIREckt1GMnt84wYMECqFbN3EViz57rzynUiYiI5BgFO7k1Z8/CM89Ahw6QmAi1akFQkNVViYiI5EoKdpJ169ZB1armunR58sCIEbBxI5QsaXVlIiIiuZLusZOs6d/fnOUKUK4cfPgh1KljbU0iIiK5nHrsJGuCg83/dusG27cr1ImIiLgA9dhJ5thscPo0hIebx/36QcOG0KiRtXWJiIiInXrs5L+dOAFNmpiPy5fNNh8fhToREREXo2AnN7dokTlBYv16OHoUduywuiIRERHJgIKdpO/cOXNNutatzZ/r1YOdO6F+fYsLExERkYwo2MmNNmwwe+k++sgcch02DDZvhrJlra5MREREbkKTJyQtw4A33zTvqytd2lzG5M47ra5KREREMkE9dpKWlxfMmQM9ephDrwp1IiIibkPBLrez2WDiRHj11ettxYvDpEmQL591dYmIiIjDcu1QbFKSeftYVq7zGH/+CZ07w5o15vETT6iHTkRExI3l2mBXtKjVFVhs6VLo2hX+/hsCA+Gdd8yZryIiIuK2cm2wu1UNG0JQkNVVZEFiIvTqBfPmmce1apkTJCpUsLYuERERuWW5NtgdOnR9d6ysCAoy5xm4FcOAxo1h2zbw9oYBA2DIEPDzs7oyERERcYJcG+yCgiBvXquryGFeXvDaa+Y+rwsWwF13WV2RiIiIOJFmxXq6/fvN7cCuefpp2LtXoU5ERMQDKdh5KsOAqVOhZk2Ijoa4uOvPBQZaV5eIiIhkm1w7FOvRYmPh2Wfhq6/M47vuMterExEREY+mHjtP89lnUKWKGer8/WHCBFi1CiIirK5MREREspl67DxFaip06wYzZ5rH1arBwoVwxx3W1iUiIiI5Rj12nsLHxxxuvTbz9YcfFOpERERyGfXYubMrV+DCBShY0DyeMAE6doR77rG0LBEREbGGeuzc1W+/mZMiWrc2Z8AC5M+vUCciIpKLKdi5G8OAGTOgenX48Uf4/nsz5ImIiEiup2DnTk6fhpYtoWtXuHgR7rsPdu+GcuWsrkxERERcgIKdu1ixwlzGZPlyc2/Xd96BtWshMtLqykRERMRFaPKEO7hyBWJizB67ypXNZUyqVrW6KhGRXC01NZUrV65YXYa4KB8fH/LkyYOXl1eOvq+CnTvw9YUPP4RFi2DkSAgIsLoiEZFc7cKFC/zxxx8Y1yaviaQjKCiIiIgI/Pz8cuw9Fexc0dWrMGaMOcu1Vy+zrU4d8yEiIpZKTU3ljz/+ICgoiCJFiuR4j4y4PsMwSElJ4cyZMxw9epSyZcvi7Z0zd78p2LmaI0egfXv47jvzXrrHHoOoKKurEhGR/3flyhUMw6BIkSIEBgZaXY64qMDAQHx9ffn9999JSUkhIIdG2zR5wlUYBsyZY24F9t13EBwMs2ZBiRJWVyYiIulQT538l5zqpfsn9di5gr/+MpcwWbbMPL7nHpg/X6FOREREHKJgZ7XLl6FWLfj9d3OSxJtvQt++5t6vIiIiIg7QUKzVAgKgWzeoWBF++AH69VOoExGRbLN161Z8fHx45JFHbnhuw4YNeHl5ce7cuRuei4qKYsKECWna1q9fz8MPP8xtt91GUFAQlSpV4pVXXuHPP//Mpurh8uXLdO/endtuu418+fLxxBNPEBcXd9NrvLy80n2MHTvWfs727dt54IEHKFCgALfddhtdu3blwoULN7zW3LlzqVq1KgEBAYSGhtK9e3enf8ZboWBnhR074Jdfrh+/+ips2wY1alhXk4iI5AqzZs2iZ8+efPvtt5w8eTLLrzN9+nSaNGlCeHg4n3zyCXv37mXatGkkJCQwbtw4J1acVp8+ffjiiy/4+OOP2bhxIydPnqRVq1Y3vebUqVNpHrNnz8bLy4snnngCgJMnT9KkSRPKlCnDDz/8wKpVq9izZw+dOnVK8zrjx4/n9ddfp3///uzZs4e1a9fSrFmz7PqoWWPkMgkJCQZgnDyZkPNvfvWqYYwebRi+voZRqZJhXLyY8zWIiMgtuXTpkrF3717j0qVLVpfisPPnzxv58uUz9u/fb0RHRxsjR45M8/z69esNwPj7779vuLZEiRLGu+++axiGYZw4ccLw8/MzXn755XTfJ73rneHcuXOGr6+v8fHHH9vb9u3bZwDG1q1bM/06LVq0MBo3bmw/nj59uhEaGmqkpqba23755RcDMH777TfDMAzj7NmzRmBgoLF27dpMv8/Nfq9cyyMJCc7NI+qxyynHjpl7u/bvb+4kUb48JCdbXZWIiNwiw4CkJGsejq6PvGTJEipUqED58uVp164ds2fPztIiyx9//DEpKSm89tpr6T5foECBDK996KGHyJcvX4aPO+64I8Nrt23bxpUrV2jSpIm9rUKFChQvXpytW7dmqva4uDhWrFhBly5d7G3Jycn4+fmlmcV6bSmbzZs3A7BmzRpsNht//vknFStW5Pbbb+fpp5/mxIkTmXrfnKLJE9nNMMxdI3r0gMREyJcP3nsPOnUCTZUXEXF7Fy+af7Vb4cIFyJs38+fPmjWLdu3aAfDggw+SkJDAxo0buffeex16399++43g4GAiIiIcug5g5syZXLp0KcPnfX19M3wuNjYWPz+/G4JjWFgYsbGxmXr/efPmkT9//jTDt40bNyYmJoaxY8fSu3dvkpKS6N+/P2AO4wIcOXIEm83GW2+9xcSJEwkJCWHQoEE88MAD/PLLLzm6u8TNKNhlp6QkePZZWLLEPG7QABYsgFKlrK1LRERynQMHDvDjjz/y6aefApAnTx6io6OZNWuWw8HOMIwsr+NXrFixLF3nLLNnz6Zt27ZpFgy+4447mDdvHjExMQwYMAAfHx969epFWFiYvRfPZrNx5coV3nvvPZo2bQrA//73P8LDw1m/fr3L3GunYJedAgPhzBlzluuwYeYwbB79kouIeJKgILPnzKr3zqxZs2Zx9epVihYtam8zDAN/f38mT55MSEgIwcHBACQkJNzQK3bu3DlCQkIAKFeuHAkJCZw6dcrhXruHHnqITZs2Zfh8iRIl2LNnT7rPhYeHk5KSwrlz59LUFxcXR3h4+H++96ZNmzhw4ACLFy++4bk2bdrQpk0b4uLiyJs3L15eXowfP55S/98Zc+1zVqpUyX5NkSJFKFy4MMePH//P984pShnOdvky2GzmnzZvb5g3D06dgrp1ra5MRESygZeXY8OhVrh69Srz589n3Lhx9t6ma1q2bMn//vc/unXrZt/TdNu2bZT4xyL5R44cISEhgXLlygHw5JNP0r9/f95++23efffdG97v38Hrn25lKLZWrVr4+vqybt06+4zWAwcOcPz4cerXr5/hddfMmjWLWrVqUa1atQzPCQsLA8yevYCAAB544AEAGjZsaH+/22+/HYCzZ88SHx+f5tfKck6diuEGsnVW7K5dhlG5smF06+b81xYREZfgjrNiP/30U8PPz884d+7cDc+99tprRu3ate3HXbt2NaKioozPP//cOHLkiLFx40bjzjvvNO68807DZrPZz5syZYrh5eVlPPvss8aGDRuMY8eOGZs3bza6du1qxMTEZNtn6datm1G8eHHjm2++MX7++Wejfv36Rv369dOcU758eWPZsmVp2hISEoygoCDj/fffT/d1J02aZGzbts04cOCAMXnyZCMwMNCYOHFimnNatGhh3HHHHcaWLVuM3bt3G48++qhRqVIlIyUlJd3XtGJWrIKdM6SmGsY77xiGn59hgGGEhRlGfLzzXl9ERFyGOwa7Rx991Hj44YfTfe6HH34wAGPXrl2GYZifb+jQoUaFChWMwMBAo2TJkkbXrl2NM2fO3HDtmjVrjGbNmhkFCxY0AgICjAoVKhh9+/Y1Tp48mW2f5dKlS8ZLL71kFCxY0AgKCjIef/xx49SpU2nOAYw5c+akaZs+fboRGBiYbrg1DMNo3769UahQIcPPz8+oWrWqMX/+/BvOSUhIMJ599lmjQIECRqFChYzHH3/cOH78+E1rzelg52UYWZjn7MYSExMJCQnh5MkEIiKCb/0FT5yAjh1h/XrzuHlzmDkTQkNv/bVFRMTlXL58maNHj1KyZMk0N+CL/NvNfq9cyyMJCQn2exudQevY3YpFi6BqVTPUBQXB9Onw+ecKdSIiImIJTZ7Iqr//hu7d4dw5c2LEggXw/zeVioiIiFhBwS6rChaEDz4w93wdNAhuMotHREREJCdoKDazkpOhXz9zqPWaJ56A4cMV6kRERMQlqMcuM/bsgXbtYOdOKFzY3PPViTc6ioiIiDiDeuxuxmYz93WtVet6qJsxQ6FORETIZYtKSBZY8XtEPXYZOXkSOneGr782jx96CGbPhkxsWSIiIp7Lx8cHgJSUFAIDAy2uRlzZxYsXgZvvpuFsCnbpOX3aXMbkr78gIADGjYMXXzT3jRERkVwtT548BAUFcebMGXx9fe2bxItcYxgGFy9e5PTp0xQoUMD+j4GcoGCXntBQaNUKtm2DhQuhQgWrKxIRERfh5eVFREQER48e5ffff7e6HHFhBQoUIDyHR/oU7K7ZsgWioqBYMfN4wgTIkwf8/KysSkREXJCfnx9ly5YlJSXF6lLERfn6+uZoT901LhHspkyZwtixY4mNjaVatWpMmjSJunXrZnj+xx9/zODBgzl27Bhly5ZlzJgxPPzww1l785QUc8mS0aPh/vth1Srw9jZ3khAREcmAt7e3thQTl2P5jQGLFy8mJiaGoUOHsn37dqpVq0azZs04ffp0uud/9913tG7dmi5durBjxw5atmxJy5Yt+fXXXx1/8/37oUEDeOstcwZsRIS5Xp2IiIiIG/IyLJ6vXa9ePerUqcPkyZMBsNlsREZG0rNnT/r373/D+dHR0SQlJfHll1/a2+68806qV6/OtGnT/vP9rm26e3rUOIq8MQguXTJ3kZg+HZ56ynkfTERERCQD1/JIQkICwU5cRs3SHruUlBS2bdtGkyZN7G3e3t40adKErVu3pnvN1q1b05wP0KxZswzPz4j/gFfMUNekCezerVAnIiIibs/Se+zi4+NJTU0lLCwsTXtYWBj79+9P95rY2Nh0z4+NjU33/OTkZJL/MbyakJBg/tfXF958E154wbynLjHxVj6KiIiISKYl/n/ucPbAqUtMnshOo0aNYvjw4Te0F79yBfr3Nx8iIiIiFvjrr78ICQlx2utZGuwKFy6Mj48PcXFxadrj4uIyXPclPDzcofMHDBhATEyM/fjcuXOUKFGC48ePO/UXUrJXYmIikZGRnDhxwqn3Ikj20XfmnvS9uR99Z+4pISGB4sWLU6hQIae+rqXBzs/Pj1q1arFu3TpatmwJmJMn1q1bR48ePdK9pn79+qxbt46XX37Z3rZmzRrq16+f7vn+/v74+/vf0B4SEqI/AG4oODhY35ub0XfmnvS9uR99Z+7J2TuXWD4UGxMTQ8eOHalduzZ169ZlwoQJJCUl0blzZwA6dOhAsWLFGDVqFAC9e/emUaNGjBs3jkceeYRFixbx888/88EHH1j5MUREREQsZ3mwi46O5syZMwwZMoTY2FiqV6/OqlWr7BMkjh8/nibNNmjQgI8++ohBgwYxcOBAypYty2effUblypWt+ggiIiIiLsHyYAfQo0ePDIdeN2zYcEPbU089xVNZXJ7E39+foUOHpjs8K65L35v70XfmnvS9uR99Z+4pu743yxcoFhERERHnsHxLMRERERFxDgU7EREREQ+hYCciIiLiITwy2E2ZMoWoqCgCAgKoV68eP/74403P//jjj6lQoQIBAQFUqVKFlStX5lCl8k+OfG8zZszg7rvvpmDBghQsWJAmTZr85/cszufon7VrFi1ahJeXl339SslZjn5v586do3v37kRERODv70+5cuX092QOc/Q7mzBhAuXLlycwMJDIyEj69OnD5cuXc6haAfj2229p3rw5RYsWxcvLi88+++w/r9mwYQM1a9bE39+fMmXKMHfuXMff2PAwixYtMvz8/IzZs2cbe/bsMZ5//nmjQIECRlxcXLrnb9myxfDx8THefvttY+/evcagQYMMX19fY/fu3Tlcee7m6PfWpk0bY8qUKcaOHTuMffv2GZ06dTJCQkKMP/74I4crz70c/c6uOXr0qFGsWDHj7rvvNlq0aJEzxYqdo99bcnKyUbt2bePhhx82Nm/ebBw9etTYsGGDsXPnzhyuPPdy9DtbuHCh4e/vbyxcuNA4evSosXr1aiMiIsLo06dPDleeu61cudJ4/fXXjWXLlhmA8emnn970/CNHjhhBQUFGTEyMsXfvXmPSpEmGj4+PsWrVKofe1+OCXd26dY3u3bvbj1NTU42iRYsao0aNSvf8p59+2njkkUfStNWrV8944YUXsrVOScvR7+3frl69auTPn9+YN29edpUo/5KV7+zq1atGgwYNjJkzZxodO3ZUsLOAo9/b+++/b5QqVcpISUnJqRLlXxz9zrp37240btw4TVtMTIzRsGHDbK1TMpaZYPfaa68Zd9xxR5q26Ohoo1mzZg69l0cNxaakpLBt2zaaNGlib/P29qZJkyZs3bo13Wu2bt2a5nyAZs2aZXi+OF9Wvrd/u3jxIleuXHH6nnuSvqx+Z2+88QahoaF06dIlJ8qUf8nK97Z8+XLq169P9+7dCQsLo3Llyrz11lukpqbmVNm5Wla+swYNGrBt2zb7cO2RI0dYuXIlDz/8cI7ULFnjrDziEgsUO0t8fDypqan2XSuuCQsLY//+/eleExsbm+75sbGx2VanpJWV7+3f+vXrR9GiRW/4QyHZIyvf2ebNm5k1axY7d+7MgQolPVn53o4cOcI333xD27ZtWblyJYcOHeKll17iypUrDB06NCfKztWy8p21adOG+Ph47rrrLgzD4OrVq3Tr1o2BAwfmRMmSRRnlkcTERC5dukRgYGCmXsejeuwkdxo9ejSLFi3i008/JSAgwOpyJB3nz5+nffv2zJgxg8KFC1tdjjjAZrMRGhrKBx98QK1atYiOjub1119n2rRpVpcmGdiwYQNvvfUWU6dOZfv27SxbtowVK1bw5ptvWl2a5ACP6rErXLgwPj4+xMXFpWmPi4sjPDw83WvCw8MdOl+cLyvf2zXvvPMOo0ePZu3atVStWjU7y5R/cPQ7O3z4MMeOHaN58+b2NpvNBkCePHk4cOAApUuXzt6iJUt/1iIiIvD19cXHx8feVrFiRWJjY0lJScHPzy9ba87tsvKdDR48mPbt2/Pcc88BUKVKFZKSkujatSuvv/56mv3XxXVklEeCg4Mz3VsHHtZj5+fnR61atVi3bp29zWazsW7dOurXr5/uNfXr109zPsCaNWsyPF+cLyvfG8Dbb7/Nm2++yapVq6hdu3ZOlCr/z9HvrEKFCuzevZudO3faH4899hj33XcfO3fuJDIyMifLz7Wy8metYcOGHDp0yB7EAQ4ePEhERIRCXQ7Iynd28eLFG8LbtWBuaBdRl+W0POLYvA7Xt2jRIsPf39+YO3eusXfvXqNr165GgQIFjNjYWMMwDKN9+/ZG//797edv2bLFyJMnj/HOO+8Y+/btM4YOHarlTizg6Pc2evRow8/Pz1i6dKlx6tQp++P8+fNWfYRcx9Hv7N80K9Yajn5vx48fN/Lnz2/06NHDOHDggPHll18aoaGhxogRI6z6CLmOo9/Z0KFDjfz58xv/+9//jCNHjhhff/21Ubp0aePpp5+26iPkSufPnzd27Nhh7NixwwCM8ePHGzt27DB+//13wzAMo3///kb79u3t519b7uTVV1819u3bZ0yZMkXLnVwzadIko3jx4oafn59Rt25d4/vvv7c/16hRI6Njx45pzl+yZIlRrlw5w8/Pz7jjjjuMFStW5HDFYhiOfW8lSpQwgBseQ4cOzfnCczFH/6z9k4KddRz93r777jujXr16hr+/v1GqVClj5MiRxtWrV3O46tzNke/sypUrxrBhw4zSpUsbAQEBRmRkpPHSSy8Zf//9d84XnoutX78+3f9PXfuuOnbsaDRq1OiGa6pXr274+fkZpUqVMubMmePw+3oZhvplRURERDyBR91jJyIiIpKbKdiJiIiIeAgFOxEREREPoWAnIiIi4iEU7EREREQ8hIKdiIiIiIdQsBMRERHxEAp2IiIiIh5CwU5ELDF37lwKFChgdRlZ5uXlxWeffXbTczp16kTLli1zpB4REVCwE5Fb0KlTJ7y8vG54HDp0yOrSmDt3rr0eb29vbr/9djp37szp06ed8vqnTp3ioYceAuDYsWN4eXmxc+fONOdMnDiRuXPnOuX9MjJs2DD75/Tx8SEyMpKuXbty9uxZh15HIVTEM+SxugARcW8PPvggc+bMSdNWpEgRi6pJKzg4mAMHDmCz2di1axedO3fm5MmTrF69+pZfOzw8/D/PCQkJueX3yYw77riDtWvXkpqayr59+3j22WdJSEhg8eLFOfL+IuI61GMnIrfE39+f8PDwNA8fHx/Gjx9PlSpVyJs3L5GRkbz00ktcuHAhw9fZtWsX9913H/nz5yc4OJhatWrx888/25/fvHkzd999N4GBgURGRtKrVy+SkpJuWpuXlxfh4eEULVqUhx56iF69erF27VouXbqEzWbjjTfe4Pbbb8ff35/q1auzatUq+7UpKSn06NGDiIgIAgICKFGiBKNGjUrz2teGYkuWLAlAjRo18PLy4t577wXS9oJ98MEHFC1aFJvNlqbGFi1a8Oyzz9qPP//8c2rWrElAQAClSpVi+PDhXL169aafM0+ePISHh1OsWDGaNGnCU089xZo1a+zPp6am0qVLF0qWLElgYCDly5dn4sSJ9ueHDRvGvHnz+Pzzz+29fxs2bADgxIkTPP300xQoUIBChQrRokULjh07dtN6RMQ6CnYiki28vb1577332LNnD/PmzeObb77htddey/D8tm3bcvvtt/PTTz+xbds2+vfvj6+vLwCHDx/mwQcf5IknnuCXX35h8eLFbN68mR49ejhUU2BgIDabjatXrzJx4kTGjRvHO++8wy+//EKzZs147LHH+O233wB47733WL58OUuWLOHAgQMsXLiQqKiodF/3xx9/BGDt2rWcOnWKZcuW3XDOU089xV9//cX69evtbWfPnmXVqlW0bdsWgE2bNtGhQwd69+7N3r17mT59OnPnzmXkyJGZ/ozHjh1j9erV+Pn52dtsNhu33347H3/8MXv37mXIkCEMHDiQJUuWANC3b1+efvppHnzwQU6dOsWpU6do0KABV65coVmzZuTPn59NmzaxZcsW8uXLx4MPPkhKSkqmaxKRHGSIiGRRx44dDR8fHyNv3rz2x5NPPpnuuR9//LFx22232Y/nzJljhISE2I/z589vzJ07N91ru3TpYnTt2jVN26ZNmwxvb2/j0qVL6V7z79c/ePCgUa5cOaN27dqGYRhG0aJFjZEjR6a5pk6dOsZLL71kGIZh9OzZ02jcuLFhs9nSfX3A+PTTTw3DMIyjR48agLFjx44053Ts2NFo0aKF/bhFixbGs88+az+ePn26UbRoUSM1NdUwDMO4//77jbfeeivNayxYsMCIiIhItwbDMIyhQ4ca3t7eRt68eY2AgAADMABj/PjxGV5jGIbRvXt344knnsiw1mvvXb58+TS/BsnJyUZgYKCxevXqm76+iFhD99iJyC257777eP/99+3HefPmBczeq1GjRrF//34SExO5evUqly9f5uLFiwQFBd3wOjExMTz33HMsWLDAPpxYunRpwBym/eWXX1i4cKH9fMMwsNlsHD16lIoVK6ZbW0JCAvny5cNms3H58mXuuusuZs6cSWJiIidPnqRhw4Zpzm/YsCG7du0CzGHUBx54gPLly/Pggw/y6KOP0rRp01v6tWrbti3PP/88U6dOxd/fn4ULF/LMM8/g7e1t/5xbtmxJ00OXmpp60183gPLly7N8+XIuX77Mhx9+yM6dO+nZs2eac6ZMmcLs2bM5fvw4ly5dIiUlherVq9+03l27dnHo0CHy58+fpv3y5cscPnw4C78CIpLdFOxE5JbkzZuXMmXKpGk7duwYjz76KC+++CIjR46kUKFCbN68mS5dupCSkpJuQBk2bBht2rRhxYoVfPXVVwwdOpRFixbx+OOPc+HCBV544QV69ep1w3XFixfPsLb8+fOzfft2vL29iYiIIDAwEIDExMT//Fw1a9bk6NGjfPXVV6xdu5ann36aJk2asHTp0v+8NiPNmzfHMAxWrFhBnTp12LRpE++++679+QsXLjB8+HBatWp1w7UBAQEZvq6fn5/9Oxg9ejSPPPIIw4cP58033wRg0aJF9O3bl3HjxlG/fn3y58/P2LFj+eGHH25a74ULF6hVq1aaQH2Nq0yQEZG0FOxExOm2bduGzWZj3Lhx9t6oa/dz3Uy5cuUoV64cffr0oXXr1syZM4fHH3+cmjVrsnfv3hsC5H/x9vZO95rg4GCKFi3Kli1baNSokb19y5Yt1K1bN8150dHRREdH8+STT/Lggw9y9uxZChUqlOb1rt3PlpqaetN6AgICaNWqFQsXLuTQoUOUL1+emjVr2p+vWbMmBw4ccPhz/tugQYNo3LgxL774ov1zNmjQgJdeesl+zr973Pz8/G6ov2bNmixevJjQ0FCCg4NvqSYRyRmaPCEiTlemTBmuXLnCpEmTOHLkCAsWLGDatGkZnn/p0iV69OjBhg0b+P3339myZQs//fSTfYi1X79+fPfdd/To0YOdO3fy22+/8fnnnzs8eeKfXn31VcaMGcPixYs5cOAA/fv3Z+fOnfTu3RuA8ePH87///Y/9+/dz8OBBPv74Y8LDw9NdVDk0NJTAwEBWrVpFXFwcCQkJGb5v27ZtWbFiBbNnz7ZPmrhmyJAhzJ8/n+HDh7Nnzx727dvHokWLGDRokEOfrX79+lStWpW33noLgLJly/Lzzz+zevVqDh48yODBg/npp5/SXBMVFcUvv/zCgQMHiI+P58qVK7Rt25bChQvTokULNm3axNGjR9mwYQO9evXijz/+cKgmEckZCnYi4nTVqlVj/PjxjBkzhsqVK7Nw4cI0S4X8m4+PD3/99RcdOnSgXLlyPP300zz00EMMHz4cgKpVq7Jx40YOHjzI3XffTY0aNRgyZAhFixbNco29evUiJiaGV155hSpVqrBq1SqWL19O2bJlAXMY9+2336Z27drUqVOHY8eOsXLlSnsP5D/lyZOH9957j+nTp1O0aFFatGiR4fs2btyYQoUKceDAAdq0aZPmuWbNmvHll1/y9ddfU6dOHe68807effddSpQo4fDn69OnDzNnzuTEiRO88MILtGrViujoaOrVq8dff/2VpvcO4Pnnn6d8+fLUrl2bIkWKsGXLFoKCgvj2228pXrw4rVq1omLFinTp0oXLly+rB0/ERXkZhmFYXYSIiIiI3Dr12ImIiIh4CAU7EREREQ+hYCciIiLiIRTsRERERDyEgp2IiIiIh1CwExEREfEQCnYiIiIiHkLBTkRERMRDKNiJiIiIeAgFOxEREREPoWAnIiIi4iEU7EREREQ8xP8BXYgNj3PHuD8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PineBioML.report.utils import classification_summary\n",
    "\n",
    "classification_summary(y_valid, y_valid_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0a5c9",
   "metadata": {},
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9526969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PineBioML import IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f6c582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IO.save_model(model, \"./output/models/\", \"model9\", overide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b57643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
